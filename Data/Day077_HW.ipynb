{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day077_HW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RFdream/ML100-Days/blob/master/Data/Day077_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "G5RevNIa3A18",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Work\n",
        "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
        "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
      ]
    },
    {
      "metadata": {
        "id": "kMNHOAqM3A1-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Disable GPU\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KWPeW9Cp3A2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "27cf0c58-616a-4a03-a7e6-95bc25827549"
      },
      "cell_type": "code",
      "source": [
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 162s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m9jOeUgu3A2G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "# Flatten the images\n",
        "x_train = x_train.reshape((len(x_train), -1))\n",
        "x_test = x_test.reshape((len(x_test), -1))\n",
        "\n",
        "# Convert y to onehot\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SBox_dz93A2I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "da1a57bb-fd11-4415-9633-64ab2443fec5"
      },
      "cell_type": "code",
      "source": [
        "def build_mlp():\n",
        "    \"\"\"\n",
        "    Try to build your own model\n",
        "    \"\"\"\n",
        "\n",
        "    input_layer = Input([x_train.shape[-1]])\n",
        "    x = Dense(units=512, activation=\"relu\")(input_layer)\n",
        "    x = Dense(units=256, activation=\"relu\")(x)\n",
        "    x = Dense(units=128, activation=\"relu\")(x)\n",
        "    output_layer = Dense(units=10, activation=\"softmax\")(x)\n",
        "    \n",
        "    model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "    return model\n",
        "\n",
        "model = build_mlp()\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PcXKtJlP3A2L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Compile your model\n",
        "\"\"\"\n",
        "optimizer = SGD(lr=1e-3)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "PcBv4L9G3A2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17122
        },
        "outputId": "af892786-22c8-4e43-ea0f-653c1557119f"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Set epochs\n",
        "\"\"\"\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=500, \n",
        "          batch_size=256, \n",
        "          validation_data=(x_test, y_test), \n",
        "          shuffle=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 2.2556 - acc: 0.1853 - val_loss: 2.2095 - val_acc: 0.2233\n",
            "Epoch 2/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 2.1738 - acc: 0.2412 - val_loss: 2.1434 - val_acc: 0.2536\n",
            "Epoch 3/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 2.1169 - acc: 0.2615 - val_loss: 2.0926 - val_acc: 0.2767\n",
            "Epoch 4/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 2.0728 - acc: 0.2769 - val_loss: 2.0543 - val_acc: 0.2870\n",
            "Epoch 5/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 2.0384 - acc: 0.2887 - val_loss: 2.0233 - val_acc: 0.2980\n",
            "Epoch 6/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 2.0101 - acc: 0.2960 - val_loss: 1.9979 - val_acc: 0.3068\n",
            "Epoch 7/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.9858 - acc: 0.3054 - val_loss: 1.9748 - val_acc: 0.3144\n",
            "Epoch 8/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.9641 - acc: 0.3134 - val_loss: 1.9545 - val_acc: 0.3209\n",
            "Epoch 9/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.9449 - acc: 0.3201 - val_loss: 1.9370 - val_acc: 0.3293\n",
            "Epoch 10/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.9279 - acc: 0.3278 - val_loss: 1.9213 - val_acc: 0.3336\n",
            "Epoch 11/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.9123 - acc: 0.3336 - val_loss: 1.9061 - val_acc: 0.3409\n",
            "Epoch 12/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.8982 - acc: 0.3401 - val_loss: 1.8944 - val_acc: 0.3380\n",
            "Epoch 13/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.8854 - acc: 0.3445 - val_loss: 1.8815 - val_acc: 0.3457\n",
            "Epoch 14/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.8735 - acc: 0.3488 - val_loss: 1.8700 - val_acc: 0.3525\n",
            "Epoch 15/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.8624 - acc: 0.3525 - val_loss: 1.8597 - val_acc: 0.3565\n",
            "Epoch 16/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.8524 - acc: 0.3561 - val_loss: 1.8517 - val_acc: 0.3552\n",
            "Epoch 17/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.8431 - acc: 0.3602 - val_loss: 1.8413 - val_acc: 0.3613\n",
            "Epoch 18/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.8342 - acc: 0.3637 - val_loss: 1.8351 - val_acc: 0.3574\n",
            "Epoch 19/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.8260 - acc: 0.3657 - val_loss: 1.8258 - val_acc: 0.3663\n",
            "Epoch 20/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.8182 - acc: 0.3682 - val_loss: 1.8177 - val_acc: 0.3725\n",
            "Epoch 21/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.8106 - acc: 0.3707 - val_loss: 1.8116 - val_acc: 0.3727\n",
            "Epoch 22/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.8035 - acc: 0.3728 - val_loss: 1.8042 - val_acc: 0.3755\n",
            "Epoch 23/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7968 - acc: 0.3753 - val_loss: 1.7983 - val_acc: 0.3730\n",
            "Epoch 24/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.7903 - acc: 0.3785 - val_loss: 1.7923 - val_acc: 0.3769\n",
            "Epoch 25/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7845 - acc: 0.3786 - val_loss: 1.7851 - val_acc: 0.3787\n",
            "Epoch 26/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7784 - acc: 0.3820 - val_loss: 1.7796 - val_acc: 0.3793\n",
            "Epoch 27/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7724 - acc: 0.3829 - val_loss: 1.7755 - val_acc: 0.3809\n",
            "Epoch 28/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7670 - acc: 0.3851 - val_loss: 1.7691 - val_acc: 0.3873\n",
            "Epoch 29/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.7614 - acc: 0.3867 - val_loss: 1.7652 - val_acc: 0.3827\n",
            "Epoch 30/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7562 - acc: 0.3881 - val_loss: 1.7584 - val_acc: 0.3906\n",
            "Epoch 31/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.7509 - acc: 0.3906 - val_loss: 1.7531 - val_acc: 0.3878\n",
            "Epoch 32/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7459 - acc: 0.3929 - val_loss: 1.7484 - val_acc: 0.3889\n",
            "Epoch 33/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7410 - acc: 0.3929 - val_loss: 1.7434 - val_acc: 0.3903\n",
            "Epoch 34/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7361 - acc: 0.3964 - val_loss: 1.7393 - val_acc: 0.3911\n",
            "Epoch 35/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.7313 - acc: 0.3968 - val_loss: 1.7337 - val_acc: 0.3941\n",
            "Epoch 36/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.7267 - acc: 0.3986 - val_loss: 1.7307 - val_acc: 0.3970\n",
            "Epoch 37/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.7223 - acc: 0.4003 - val_loss: 1.7260 - val_acc: 0.3947\n",
            "Epoch 38/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.7180 - acc: 0.4020 - val_loss: 1.7221 - val_acc: 0.3995\n",
            "Epoch 39/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.7138 - acc: 0.4038 - val_loss: 1.7178 - val_acc: 0.3986\n",
            "Epoch 40/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7098 - acc: 0.4048 - val_loss: 1.7136 - val_acc: 0.4019\n",
            "Epoch 41/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.7056 - acc: 0.4062 - val_loss: 1.7100 - val_acc: 0.4055\n",
            "Epoch 42/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.7017 - acc: 0.4073 - val_loss: 1.7082 - val_acc: 0.3996\n",
            "Epoch 43/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6976 - acc: 0.4092 - val_loss: 1.7030 - val_acc: 0.4083\n",
            "Epoch 44/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6943 - acc: 0.4102 - val_loss: 1.6988 - val_acc: 0.4054\n",
            "Epoch 45/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6904 - acc: 0.4115 - val_loss: 1.6981 - val_acc: 0.4052\n",
            "Epoch 46/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.6867 - acc: 0.4124 - val_loss: 1.6925 - val_acc: 0.4105\n",
            "Epoch 47/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6832 - acc: 0.4145 - val_loss: 1.6885 - val_acc: 0.4097\n",
            "Epoch 48/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6797 - acc: 0.4154 - val_loss: 1.6852 - val_acc: 0.4130\n",
            "Epoch 49/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.6762 - acc: 0.4168 - val_loss: 1.6818 - val_acc: 0.4115\n",
            "Epoch 50/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6727 - acc: 0.4178 - val_loss: 1.6796 - val_acc: 0.4128\n",
            "Epoch 51/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6694 - acc: 0.4193 - val_loss: 1.6750 - val_acc: 0.4149\n",
            "Epoch 52/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6660 - acc: 0.4202 - val_loss: 1.6726 - val_acc: 0.4185\n",
            "Epoch 53/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6626 - acc: 0.4211 - val_loss: 1.6690 - val_acc: 0.4167\n",
            "Epoch 54/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6597 - acc: 0.4224 - val_loss: 1.6700 - val_acc: 0.4167\n",
            "Epoch 55/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6564 - acc: 0.4236 - val_loss: 1.6656 - val_acc: 0.4194\n",
            "Epoch 56/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6537 - acc: 0.4251 - val_loss: 1.6605 - val_acc: 0.4212\n",
            "Epoch 57/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6504 - acc: 0.4262 - val_loss: 1.6575 - val_acc: 0.4219\n",
            "Epoch 58/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.6473 - acc: 0.4259 - val_loss: 1.6563 - val_acc: 0.4258\n",
            "Epoch 59/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6442 - acc: 0.4277 - val_loss: 1.6513 - val_acc: 0.4246\n",
            "Epoch 60/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6416 - acc: 0.4288 - val_loss: 1.6486 - val_acc: 0.4247\n",
            "Epoch 61/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6385 - acc: 0.4290 - val_loss: 1.6470 - val_acc: 0.4249\n",
            "Epoch 62/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6353 - acc: 0.4303 - val_loss: 1.6453 - val_acc: 0.4257\n",
            "Epoch 63/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.6328 - acc: 0.4323 - val_loss: 1.6424 - val_acc: 0.4245\n",
            "Epoch 64/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.6300 - acc: 0.4331 - val_loss: 1.6384 - val_acc: 0.4306\n",
            "Epoch 65/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6272 - acc: 0.4337 - val_loss: 1.6365 - val_acc: 0.4281\n",
            "Epoch 66/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6246 - acc: 0.4342 - val_loss: 1.6336 - val_acc: 0.4315\n",
            "Epoch 67/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6217 - acc: 0.4352 - val_loss: 1.6314 - val_acc: 0.4282\n",
            "Epoch 68/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6193 - acc: 0.4363 - val_loss: 1.6295 - val_acc: 0.4307\n",
            "Epoch 69/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.6167 - acc: 0.4375 - val_loss: 1.6272 - val_acc: 0.4330\n",
            "Epoch 70/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6141 - acc: 0.4385 - val_loss: 1.6259 - val_acc: 0.4341\n",
            "Epoch 71/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6115 - acc: 0.4390 - val_loss: 1.6222 - val_acc: 0.4302\n",
            "Epoch 72/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6088 - acc: 0.4397 - val_loss: 1.6200 - val_acc: 0.4358\n",
            "Epoch 73/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6064 - acc: 0.4421 - val_loss: 1.6210 - val_acc: 0.4330\n",
            "Epoch 74/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.6042 - acc: 0.4407 - val_loss: 1.6154 - val_acc: 0.4378\n",
            "Epoch 75/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6018 - acc: 0.4428 - val_loss: 1.6140 - val_acc: 0.4381\n",
            "Epoch 76/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5995 - acc: 0.4437 - val_loss: 1.6125 - val_acc: 0.4356\n",
            "Epoch 77/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5970 - acc: 0.4439 - val_loss: 1.6089 - val_acc: 0.4366\n",
            "Epoch 78/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5945 - acc: 0.4436 - val_loss: 1.6059 - val_acc: 0.4426\n",
            "Epoch 79/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5925 - acc: 0.4451 - val_loss: 1.6116 - val_acc: 0.4368\n",
            "Epoch 80/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5900 - acc: 0.4446 - val_loss: 1.6029 - val_acc: 0.4405\n",
            "Epoch 81/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5877 - acc: 0.4469 - val_loss: 1.6030 - val_acc: 0.4400\n",
            "Epoch 82/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5856 - acc: 0.4468 - val_loss: 1.6015 - val_acc: 0.4423\n",
            "Epoch 83/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5831 - acc: 0.4480 - val_loss: 1.6008 - val_acc: 0.4417\n",
            "Epoch 84/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5810 - acc: 0.4480 - val_loss: 1.6003 - val_acc: 0.4412\n",
            "Epoch 85/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5787 - acc: 0.4485 - val_loss: 1.5949 - val_acc: 0.4456\n",
            "Epoch 86/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5765 - acc: 0.4501 - val_loss: 1.5949 - val_acc: 0.4410\n",
            "Epoch 87/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5747 - acc: 0.4514 - val_loss: 1.5956 - val_acc: 0.4447\n",
            "Epoch 88/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5725 - acc: 0.4521 - val_loss: 1.5934 - val_acc: 0.4446\n",
            "Epoch 89/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5705 - acc: 0.4537 - val_loss: 1.5885 - val_acc: 0.4486\n",
            "Epoch 90/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5682 - acc: 0.4522 - val_loss: 1.5878 - val_acc: 0.4447\n",
            "Epoch 91/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5662 - acc: 0.4531 - val_loss: 1.5832 - val_acc: 0.4499\n",
            "Epoch 92/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5642 - acc: 0.4541 - val_loss: 1.5852 - val_acc: 0.4511\n",
            "Epoch 93/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5624 - acc: 0.4554 - val_loss: 1.5829 - val_acc: 0.4520\n",
            "Epoch 94/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5601 - acc: 0.4562 - val_loss: 1.5775 - val_acc: 0.4490\n",
            "Epoch 95/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5581 - acc: 0.4570 - val_loss: 1.5778 - val_acc: 0.4496\n",
            "Epoch 96/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5561 - acc: 0.4574 - val_loss: 1.5823 - val_acc: 0.4485\n",
            "Epoch 97/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5544 - acc: 0.4587 - val_loss: 1.5735 - val_acc: 0.4525\n",
            "Epoch 98/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5522 - acc: 0.4581 - val_loss: 1.5715 - val_acc: 0.4536\n",
            "Epoch 99/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5503 - acc: 0.4581 - val_loss: 1.5783 - val_acc: 0.4526\n",
            "Epoch 100/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5483 - acc: 0.4599 - val_loss: 1.5678 - val_acc: 0.4533\n",
            "Epoch 101/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5464 - acc: 0.4604 - val_loss: 1.5734 - val_acc: 0.4485\n",
            "Epoch 102/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5448 - acc: 0.4604 - val_loss: 1.5649 - val_acc: 0.4558\n",
            "Epoch 103/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5423 - acc: 0.4612 - val_loss: 1.5644 - val_acc: 0.4555\n",
            "Epoch 104/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5406 - acc: 0.4625 - val_loss: 1.5646 - val_acc: 0.4571\n",
            "Epoch 105/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5388 - acc: 0.4635 - val_loss: 1.5600 - val_acc: 0.4610\n",
            "Epoch 106/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.5371 - acc: 0.4633 - val_loss: 1.5598 - val_acc: 0.4566\n",
            "Epoch 107/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.5353 - acc: 0.4645 - val_loss: 1.5588 - val_acc: 0.4561\n",
            "Epoch 108/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5329 - acc: 0.4651 - val_loss: 1.5555 - val_acc: 0.4570\n",
            "Epoch 109/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5313 - acc: 0.4651 - val_loss: 1.5542 - val_acc: 0.4578\n",
            "Epoch 110/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5295 - acc: 0.4667 - val_loss: 1.5552 - val_acc: 0.4587\n",
            "Epoch 111/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5277 - acc: 0.4661 - val_loss: 1.5509 - val_acc: 0.4597\n",
            "Epoch 112/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5260 - acc: 0.4679 - val_loss: 1.5509 - val_acc: 0.4571\n",
            "Epoch 113/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5242 - acc: 0.4686 - val_loss: 1.5477 - val_acc: 0.4630\n",
            "Epoch 114/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.5223 - acc: 0.4700 - val_loss: 1.5496 - val_acc: 0.4571\n",
            "Epoch 115/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.5207 - acc: 0.4696 - val_loss: 1.5463 - val_acc: 0.4615\n",
            "Epoch 116/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.5187 - acc: 0.4705 - val_loss: 1.5518 - val_acc: 0.4568\n",
            "Epoch 117/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5170 - acc: 0.4715 - val_loss: 1.5436 - val_acc: 0.4634\n",
            "Epoch 118/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5151 - acc: 0.4715 - val_loss: 1.5432 - val_acc: 0.4637\n",
            "Epoch 119/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5135 - acc: 0.4711 - val_loss: 1.5503 - val_acc: 0.4609\n",
            "Epoch 120/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5118 - acc: 0.4732 - val_loss: 1.5441 - val_acc: 0.4613\n",
            "Epoch 121/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5101 - acc: 0.4734 - val_loss: 1.5385 - val_acc: 0.4622\n",
            "Epoch 122/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5084 - acc: 0.4747 - val_loss: 1.5368 - val_acc: 0.4635\n",
            "Epoch 123/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.5065 - acc: 0.4747 - val_loss: 1.5354 - val_acc: 0.4665\n",
            "Epoch 124/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.5045 - acc: 0.4761 - val_loss: 1.5339 - val_acc: 0.4655\n",
            "Epoch 125/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5028 - acc: 0.4761 - val_loss: 1.5404 - val_acc: 0.4599\n",
            "Epoch 126/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5016 - acc: 0.4759 - val_loss: 1.5391 - val_acc: 0.4626\n",
            "Epoch 127/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5001 - acc: 0.4774 - val_loss: 1.5305 - val_acc: 0.4676\n",
            "Epoch 128/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4973 - acc: 0.4788 - val_loss: 1.5326 - val_acc: 0.4656\n",
            "Epoch 129/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4966 - acc: 0.4781 - val_loss: 1.5294 - val_acc: 0.4666\n",
            "Epoch 130/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.4945 - acc: 0.4790 - val_loss: 1.5273 - val_acc: 0.4685\n",
            "Epoch 131/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4931 - acc: 0.4780 - val_loss: 1.5267 - val_acc: 0.4680\n",
            "Epoch 132/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4912 - acc: 0.4804 - val_loss: 1.5224 - val_acc: 0.4695\n",
            "Epoch 133/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4899 - acc: 0.4812 - val_loss: 1.5273 - val_acc: 0.4642\n",
            "Epoch 134/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.4882 - acc: 0.4805 - val_loss: 1.5244 - val_acc: 0.4667\n",
            "Epoch 135/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4863 - acc: 0.4822 - val_loss: 1.5209 - val_acc: 0.4702\n",
            "Epoch 136/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4849 - acc: 0.4821 - val_loss: 1.5190 - val_acc: 0.4706\n",
            "Epoch 137/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4833 - acc: 0.4839 - val_loss: 1.5193 - val_acc: 0.4722\n",
            "Epoch 138/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4818 - acc: 0.4836 - val_loss: 1.5216 - val_acc: 0.4668\n",
            "Epoch 139/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4801 - acc: 0.4843 - val_loss: 1.5186 - val_acc: 0.4728\n",
            "Epoch 140/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4784 - acc: 0.4854 - val_loss: 1.5179 - val_acc: 0.4719\n",
            "Epoch 141/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4766 - acc: 0.4855 - val_loss: 1.5158 - val_acc: 0.4702\n",
            "Epoch 142/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4751 - acc: 0.4864 - val_loss: 1.5129 - val_acc: 0.4715\n",
            "Epoch 143/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.4733 - acc: 0.4867 - val_loss: 1.5128 - val_acc: 0.4722\n",
            "Epoch 144/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4720 - acc: 0.4868 - val_loss: 1.5102 - val_acc: 0.4728\n",
            "Epoch 145/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4708 - acc: 0.4878 - val_loss: 1.5081 - val_acc: 0.4761\n",
            "Epoch 146/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.4686 - acc: 0.4886 - val_loss: 1.5055 - val_acc: 0.4743\n",
            "Epoch 147/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4674 - acc: 0.4892 - val_loss: 1.5097 - val_acc: 0.4752\n",
            "Epoch 148/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4653 - acc: 0.4897 - val_loss: 1.5043 - val_acc: 0.4748\n",
            "Epoch 149/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4637 - acc: 0.4904 - val_loss: 1.5029 - val_acc: 0.4758\n",
            "Epoch 150/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4625 - acc: 0.4904 - val_loss: 1.5062 - val_acc: 0.4755\n",
            "Epoch 151/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4607 - acc: 0.4909 - val_loss: 1.5041 - val_acc: 0.4754\n",
            "Epoch 152/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4592 - acc: 0.4933 - val_loss: 1.5064 - val_acc: 0.4755\n",
            "Epoch 153/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4575 - acc: 0.4930 - val_loss: 1.5001 - val_acc: 0.4738\n",
            "Epoch 154/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4558 - acc: 0.4916 - val_loss: 1.5043 - val_acc: 0.4738\n",
            "Epoch 155/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4549 - acc: 0.4935 - val_loss: 1.4968 - val_acc: 0.4779\n",
            "Epoch 156/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4531 - acc: 0.4930 - val_loss: 1.5016 - val_acc: 0.4769\n",
            "Epoch 157/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4516 - acc: 0.4947 - val_loss: 1.4951 - val_acc: 0.4805\n",
            "Epoch 158/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.4495 - acc: 0.4943 - val_loss: 1.4950 - val_acc: 0.4784\n",
            "Epoch 159/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4484 - acc: 0.4962 - val_loss: 1.4957 - val_acc: 0.4768\n",
            "Epoch 160/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4471 - acc: 0.4965 - val_loss: 1.4959 - val_acc: 0.4774\n",
            "Epoch 161/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4453 - acc: 0.4966 - val_loss: 1.4911 - val_acc: 0.4797\n",
            "Epoch 162/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4434 - acc: 0.4965 - val_loss: 1.4920 - val_acc: 0.4793\n",
            "Epoch 163/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4426 - acc: 0.4965 - val_loss: 1.4907 - val_acc: 0.4796\n",
            "Epoch 164/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4406 - acc: 0.4989 - val_loss: 1.4949 - val_acc: 0.4793\n",
            "Epoch 165/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4390 - acc: 0.4981 - val_loss: 1.4887 - val_acc: 0.4796\n",
            "Epoch 166/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4377 - acc: 0.4987 - val_loss: 1.4873 - val_acc: 0.4798\n",
            "Epoch 167/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4361 - acc: 0.4997 - val_loss: 1.4856 - val_acc: 0.4810\n",
            "Epoch 168/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4346 - acc: 0.4994 - val_loss: 1.4809 - val_acc: 0.4854\n",
            "Epoch 169/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4332 - acc: 0.5009 - val_loss: 1.4873 - val_acc: 0.4805\n",
            "Epoch 170/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4315 - acc: 0.5009 - val_loss: 1.4839 - val_acc: 0.4775\n",
            "Epoch 171/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4299 - acc: 0.5013 - val_loss: 1.4795 - val_acc: 0.4816\n",
            "Epoch 172/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4284 - acc: 0.5022 - val_loss: 1.4789 - val_acc: 0.4827\n",
            "Epoch 173/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4270 - acc: 0.5034 - val_loss: 1.4787 - val_acc: 0.4833\n",
            "Epoch 174/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4251 - acc: 0.5030 - val_loss: 1.4758 - val_acc: 0.4829\n",
            "Epoch 175/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4235 - acc: 0.5036 - val_loss: 1.4877 - val_acc: 0.4795\n",
            "Epoch 176/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4224 - acc: 0.5036 - val_loss: 1.4817 - val_acc: 0.4790\n",
            "Epoch 177/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4207 - acc: 0.5040 - val_loss: 1.4769 - val_acc: 0.4812\n",
            "Epoch 178/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4192 - acc: 0.5052 - val_loss: 1.4755 - val_acc: 0.4803\n",
            "Epoch 179/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4176 - acc: 0.5048 - val_loss: 1.4739 - val_acc: 0.4881\n",
            "Epoch 180/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4161 - acc: 0.5063 - val_loss: 1.4745 - val_acc: 0.4815\n",
            "Epoch 181/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4148 - acc: 0.5064 - val_loss: 1.4761 - val_acc: 0.4814\n",
            "Epoch 182/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4138 - acc: 0.5063 - val_loss: 1.4714 - val_acc: 0.4834\n",
            "Epoch 183/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4118 - acc: 0.5077 - val_loss: 1.4738 - val_acc: 0.4871\n",
            "Epoch 184/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4103 - acc: 0.5080 - val_loss: 1.4695 - val_acc: 0.4837\n",
            "Epoch 185/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4087 - acc: 0.5089 - val_loss: 1.4692 - val_acc: 0.4828\n",
            "Epoch 186/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.4073 - acc: 0.5093 - val_loss: 1.4656 - val_acc: 0.4853\n",
            "Epoch 187/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4059 - acc: 0.5101 - val_loss: 1.4655 - val_acc: 0.4828\n",
            "Epoch 188/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4048 - acc: 0.5109 - val_loss: 1.4607 - val_acc: 0.4890\n",
            "Epoch 189/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4034 - acc: 0.5104 - val_loss: 1.4655 - val_acc: 0.4860\n",
            "Epoch 190/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4014 - acc: 0.5112 - val_loss: 1.4694 - val_acc: 0.4802\n",
            "Epoch 191/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4003 - acc: 0.5117 - val_loss: 1.4633 - val_acc: 0.4856\n",
            "Epoch 192/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3983 - acc: 0.5122 - val_loss: 1.4599 - val_acc: 0.4886\n",
            "Epoch 193/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3972 - acc: 0.5132 - val_loss: 1.4571 - val_acc: 0.4880\n",
            "Epoch 194/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3954 - acc: 0.5139 - val_loss: 1.4645 - val_acc: 0.4862\n",
            "Epoch 195/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3945 - acc: 0.5126 - val_loss: 1.4577 - val_acc: 0.4850\n",
            "Epoch 196/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3928 - acc: 0.5144 - val_loss: 1.4575 - val_acc: 0.4867\n",
            "Epoch 197/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3914 - acc: 0.5141 - val_loss: 1.4577 - val_acc: 0.4878\n",
            "Epoch 198/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3900 - acc: 0.5144 - val_loss: 1.4587 - val_acc: 0.4824\n",
            "Epoch 199/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3886 - acc: 0.5148 - val_loss: 1.4616 - val_acc: 0.4826\n",
            "Epoch 200/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3868 - acc: 0.5164 - val_loss: 1.4594 - val_acc: 0.4863\n",
            "Epoch 201/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3854 - acc: 0.5176 - val_loss: 1.4488 - val_acc: 0.4926\n",
            "Epoch 202/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3848 - acc: 0.5167 - val_loss: 1.4515 - val_acc: 0.4928\n",
            "Epoch 203/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3830 - acc: 0.5168 - val_loss: 1.4577 - val_acc: 0.4848\n",
            "Epoch 204/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3810 - acc: 0.5176 - val_loss: 1.4606 - val_acc: 0.4826\n",
            "Epoch 205/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3805 - acc: 0.5183 - val_loss: 1.4494 - val_acc: 0.4888\n",
            "Epoch 206/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3786 - acc: 0.5183 - val_loss: 1.4559 - val_acc: 0.4928\n",
            "Epoch 207/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3765 - acc: 0.5208 - val_loss: 1.4485 - val_acc: 0.4875\n",
            "Epoch 208/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3760 - acc: 0.5203 - val_loss: 1.4460 - val_acc: 0.4894\n",
            "Epoch 209/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3744 - acc: 0.5210 - val_loss: 1.4446 - val_acc: 0.4913\n",
            "Epoch 210/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3731 - acc: 0.5214 - val_loss: 1.4431 - val_acc: 0.4903\n",
            "Epoch 211/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3722 - acc: 0.5215 - val_loss: 1.4556 - val_acc: 0.4864\n",
            "Epoch 212/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3704 - acc: 0.5221 - val_loss: 1.4468 - val_acc: 0.4878\n",
            "Epoch 213/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3687 - acc: 0.5229 - val_loss: 1.4392 - val_acc: 0.4946\n",
            "Epoch 214/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.3672 - acc: 0.5230 - val_loss: 1.4427 - val_acc: 0.4951\n",
            "Epoch 215/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3656 - acc: 0.5234 - val_loss: 1.4389 - val_acc: 0.4925\n",
            "Epoch 216/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3643 - acc: 0.5247 - val_loss: 1.4426 - val_acc: 0.4944\n",
            "Epoch 217/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3629 - acc: 0.5239 - val_loss: 1.4423 - val_acc: 0.4926\n",
            "Epoch 218/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3621 - acc: 0.5247 - val_loss: 1.4337 - val_acc: 0.4934\n",
            "Epoch 219/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3608 - acc: 0.5259 - val_loss: 1.4403 - val_acc: 0.4902\n",
            "Epoch 220/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3590 - acc: 0.5251 - val_loss: 1.4346 - val_acc: 0.4906\n",
            "Epoch 221/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3575 - acc: 0.5276 - val_loss: 1.4329 - val_acc: 0.4973\n",
            "Epoch 222/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3560 - acc: 0.5263 - val_loss: 1.4389 - val_acc: 0.4907\n",
            "Epoch 223/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3549 - acc: 0.5264 - val_loss: 1.4437 - val_acc: 0.4925\n",
            "Epoch 224/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3536 - acc: 0.5276 - val_loss: 1.4418 - val_acc: 0.4864\n",
            "Epoch 225/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3522 - acc: 0.5277 - val_loss: 1.4296 - val_acc: 0.4971\n",
            "Epoch 226/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3510 - acc: 0.5277 - val_loss: 1.4286 - val_acc: 0.4965\n",
            "Epoch 227/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3489 - acc: 0.5291 - val_loss: 1.4274 - val_acc: 0.4968\n",
            "Epoch 228/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3479 - acc: 0.5305 - val_loss: 1.4365 - val_acc: 0.4934\n",
            "Epoch 229/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3471 - acc: 0.5295 - val_loss: 1.4309 - val_acc: 0.4965\n",
            "Epoch 230/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3451 - acc: 0.5314 - val_loss: 1.4353 - val_acc: 0.5011\n",
            "Epoch 231/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3446 - acc: 0.5302 - val_loss: 1.4238 - val_acc: 0.4991\n",
            "Epoch 232/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3426 - acc: 0.5318 - val_loss: 1.4340 - val_acc: 0.4953\n",
            "Epoch 233/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3417 - acc: 0.5315 - val_loss: 1.4288 - val_acc: 0.4920\n",
            "Epoch 234/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3404 - acc: 0.5310 - val_loss: 1.4247 - val_acc: 0.4960\n",
            "Epoch 235/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3380 - acc: 0.5331 - val_loss: 1.4311 - val_acc: 0.4953\n",
            "Epoch 236/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3380 - acc: 0.5332 - val_loss: 1.4257 - val_acc: 0.4958\n",
            "Epoch 237/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3362 - acc: 0.5329 - val_loss: 1.4194 - val_acc: 0.4992\n",
            "Epoch 238/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3348 - acc: 0.5349 - val_loss: 1.4268 - val_acc: 0.4946\n",
            "Epoch 239/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3335 - acc: 0.5345 - val_loss: 1.4177 - val_acc: 0.5017\n",
            "Epoch 240/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3324 - acc: 0.5346 - val_loss: 1.4223 - val_acc: 0.4970\n",
            "Epoch 241/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3307 - acc: 0.5348 - val_loss: 1.4252 - val_acc: 0.4940\n",
            "Epoch 242/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.3297 - acc: 0.5358 - val_loss: 1.4230 - val_acc: 0.4965\n",
            "Epoch 243/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3285 - acc: 0.5375 - val_loss: 1.4255 - val_acc: 0.4954\n",
            "Epoch 244/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3280 - acc: 0.5363 - val_loss: 1.4243 - val_acc: 0.4958\n",
            "Epoch 245/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3255 - acc: 0.5371 - val_loss: 1.4185 - val_acc: 0.4966\n",
            "Epoch 246/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3240 - acc: 0.5372 - val_loss: 1.4126 - val_acc: 0.5025\n",
            "Epoch 247/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3231 - acc: 0.5394 - val_loss: 1.4192 - val_acc: 0.4974\n",
            "Epoch 248/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3224 - acc: 0.5388 - val_loss: 1.4106 - val_acc: 0.5030\n",
            "Epoch 249/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3210 - acc: 0.5384 - val_loss: 1.4181 - val_acc: 0.4964\n",
            "Epoch 250/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3187 - acc: 0.5403 - val_loss: 1.4300 - val_acc: 0.4960\n",
            "Epoch 251/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3179 - acc: 0.5389 - val_loss: 1.4098 - val_acc: 0.5042\n",
            "Epoch 252/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3163 - acc: 0.5408 - val_loss: 1.4127 - val_acc: 0.5002\n",
            "Epoch 253/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3163 - acc: 0.5402 - val_loss: 1.4202 - val_acc: 0.4998\n",
            "Epoch 254/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3136 - acc: 0.5416 - val_loss: 1.4116 - val_acc: 0.5030\n",
            "Epoch 255/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3128 - acc: 0.5417 - val_loss: 1.4238 - val_acc: 0.4985\n",
            "Epoch 256/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3114 - acc: 0.5408 - val_loss: 1.4151 - val_acc: 0.4973\n",
            "Epoch 257/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3108 - acc: 0.5427 - val_loss: 1.4082 - val_acc: 0.5017\n",
            "Epoch 258/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3089 - acc: 0.5434 - val_loss: 1.4130 - val_acc: 0.4973\n",
            "Epoch 259/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3075 - acc: 0.5433 - val_loss: 1.4060 - val_acc: 0.5026\n",
            "Epoch 260/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3068 - acc: 0.5436 - val_loss: 1.4074 - val_acc: 0.5023\n",
            "Epoch 261/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3052 - acc: 0.5438 - val_loss: 1.4046 - val_acc: 0.5060\n",
            "Epoch 262/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3041 - acc: 0.5442 - val_loss: 1.4118 - val_acc: 0.5033\n",
            "Epoch 263/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3026 - acc: 0.5464 - val_loss: 1.4069 - val_acc: 0.5008\n",
            "Epoch 264/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3015 - acc: 0.5461 - val_loss: 1.4154 - val_acc: 0.5004\n",
            "Epoch 265/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3005 - acc: 0.5448 - val_loss: 1.4199 - val_acc: 0.4993\n",
            "Epoch 266/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2992 - acc: 0.5468 - val_loss: 1.4207 - val_acc: 0.4907\n",
            "Epoch 267/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2984 - acc: 0.5468 - val_loss: 1.4071 - val_acc: 0.5055\n",
            "Epoch 268/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2960 - acc: 0.5481 - val_loss: 1.4040 - val_acc: 0.5025\n",
            "Epoch 269/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2957 - acc: 0.5490 - val_loss: 1.4020 - val_acc: 0.5052\n",
            "Epoch 270/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.2937 - acc: 0.5490 - val_loss: 1.4406 - val_acc: 0.4949\n",
            "Epoch 271/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2935 - acc: 0.5490 - val_loss: 1.4086 - val_acc: 0.5029\n",
            "Epoch 272/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2919 - acc: 0.5491 - val_loss: 1.4109 - val_acc: 0.4991\n",
            "Epoch 273/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2907 - acc: 0.5496 - val_loss: 1.3957 - val_acc: 0.5071\n",
            "Epoch 274/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2889 - acc: 0.5495 - val_loss: 1.4078 - val_acc: 0.5056\n",
            "Epoch 275/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2883 - acc: 0.5496 - val_loss: 1.3954 - val_acc: 0.5070\n",
            "Epoch 276/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2864 - acc: 0.5501 - val_loss: 1.4035 - val_acc: 0.5078\n",
            "Epoch 277/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2858 - acc: 0.5513 - val_loss: 1.4006 - val_acc: 0.5026\n",
            "Epoch 278/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2843 - acc: 0.5517 - val_loss: 1.4042 - val_acc: 0.5056\n",
            "Epoch 279/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2828 - acc: 0.5516 - val_loss: 1.4058 - val_acc: 0.5042\n",
            "Epoch 280/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2817 - acc: 0.5528 - val_loss: 1.4026 - val_acc: 0.5076\n",
            "Epoch 281/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2802 - acc: 0.5529 - val_loss: 1.4017 - val_acc: 0.5018\n",
            "Epoch 282/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2801 - acc: 0.5531 - val_loss: 1.3954 - val_acc: 0.5097\n",
            "Epoch 283/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2786 - acc: 0.5531 - val_loss: 1.3914 - val_acc: 0.5102\n",
            "Epoch 284/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2777 - acc: 0.5538 - val_loss: 1.4266 - val_acc: 0.4983\n",
            "Epoch 285/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2758 - acc: 0.5534 - val_loss: 1.3918 - val_acc: 0.5081\n",
            "Epoch 286/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2744 - acc: 0.5548 - val_loss: 1.3924 - val_acc: 0.5083\n",
            "Epoch 287/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2733 - acc: 0.5550 - val_loss: 1.4014 - val_acc: 0.5066\n",
            "Epoch 288/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2714 - acc: 0.5555 - val_loss: 1.3980 - val_acc: 0.5087\n",
            "Epoch 289/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2703 - acc: 0.5574 - val_loss: 1.3942 - val_acc: 0.5081\n",
            "Epoch 290/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2693 - acc: 0.5577 - val_loss: 1.4010 - val_acc: 0.5051\n",
            "Epoch 291/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2683 - acc: 0.5580 - val_loss: 1.3892 - val_acc: 0.5109\n",
            "Epoch 292/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2671 - acc: 0.5561 - val_loss: 1.3918 - val_acc: 0.5092\n",
            "Epoch 293/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2664 - acc: 0.5577 - val_loss: 1.4023 - val_acc: 0.5019\n",
            "Epoch 294/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2653 - acc: 0.5578 - val_loss: 1.4132 - val_acc: 0.4928\n",
            "Epoch 295/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2647 - acc: 0.5580 - val_loss: 1.4022 - val_acc: 0.5043\n",
            "Epoch 296/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2631 - acc: 0.5585 - val_loss: 1.3861 - val_acc: 0.5126\n",
            "Epoch 297/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2616 - acc: 0.5591 - val_loss: 1.3906 - val_acc: 0.5069\n",
            "Epoch 298/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2607 - acc: 0.5597 - val_loss: 1.3829 - val_acc: 0.5141\n",
            "Epoch 299/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2597 - acc: 0.5592 - val_loss: 1.3810 - val_acc: 0.5118\n",
            "Epoch 300/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2571 - acc: 0.5607 - val_loss: 1.3826 - val_acc: 0.5108\n",
            "Epoch 301/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2568 - acc: 0.5609 - val_loss: 1.3848 - val_acc: 0.5072\n",
            "Epoch 302/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2550 - acc: 0.5606 - val_loss: 1.4023 - val_acc: 0.5025\n",
            "Epoch 303/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2540 - acc: 0.5614 - val_loss: 1.3822 - val_acc: 0.5121\n",
            "Epoch 304/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2529 - acc: 0.5623 - val_loss: 1.3853 - val_acc: 0.5127\n",
            "Epoch 305/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2520 - acc: 0.5623 - val_loss: 1.3863 - val_acc: 0.5117\n",
            "Epoch 306/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2516 - acc: 0.5613 - val_loss: 1.3898 - val_acc: 0.5053\n",
            "Epoch 307/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2505 - acc: 0.5622 - val_loss: 1.3808 - val_acc: 0.5113\n",
            "Epoch 308/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2492 - acc: 0.5630 - val_loss: 1.4105 - val_acc: 0.5039\n",
            "Epoch 309/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2484 - acc: 0.5631 - val_loss: 1.3793 - val_acc: 0.5121\n",
            "Epoch 310/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2462 - acc: 0.5637 - val_loss: 1.3904 - val_acc: 0.5091\n",
            "Epoch 311/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2446 - acc: 0.5654 - val_loss: 1.3793 - val_acc: 0.5100\n",
            "Epoch 312/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2441 - acc: 0.5645 - val_loss: 1.3818 - val_acc: 0.5116\n",
            "Epoch 313/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2436 - acc: 0.5646 - val_loss: 1.3759 - val_acc: 0.5130\n",
            "Epoch 314/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2415 - acc: 0.5652 - val_loss: 1.3915 - val_acc: 0.5065\n",
            "Epoch 315/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2414 - acc: 0.5666 - val_loss: 1.3967 - val_acc: 0.5023\n",
            "Epoch 316/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2400 - acc: 0.5648 - val_loss: 1.3754 - val_acc: 0.5130\n",
            "Epoch 317/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2383 - acc: 0.5676 - val_loss: 1.3764 - val_acc: 0.5113\n",
            "Epoch 318/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2375 - acc: 0.5672 - val_loss: 1.3799 - val_acc: 0.5136\n",
            "Epoch 319/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2357 - acc: 0.5688 - val_loss: 1.3769 - val_acc: 0.5148\n",
            "Epoch 320/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2342 - acc: 0.5685 - val_loss: 1.3855 - val_acc: 0.5085\n",
            "Epoch 321/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2342 - acc: 0.5686 - val_loss: 1.3714 - val_acc: 0.5133\n",
            "Epoch 322/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2321 - acc: 0.5683 - val_loss: 1.3952 - val_acc: 0.5028\n",
            "Epoch 323/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2316 - acc: 0.5678 - val_loss: 1.3743 - val_acc: 0.5153\n",
            "Epoch 324/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2304 - acc: 0.5681 - val_loss: 1.3794 - val_acc: 0.5116\n",
            "Epoch 325/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2294 - acc: 0.5711 - val_loss: 1.3810 - val_acc: 0.5084\n",
            "Epoch 326/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2286 - acc: 0.5702 - val_loss: 1.3915 - val_acc: 0.5046\n",
            "Epoch 327/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2270 - acc: 0.5714 - val_loss: 1.3741 - val_acc: 0.5148\n",
            "Epoch 328/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2264 - acc: 0.5717 - val_loss: 1.3757 - val_acc: 0.5146\n",
            "Epoch 329/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2245 - acc: 0.5710 - val_loss: 1.3786 - val_acc: 0.5081\n",
            "Epoch 330/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2230 - acc: 0.5729 - val_loss: 1.3845 - val_acc: 0.5054\n",
            "Epoch 331/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2225 - acc: 0.5722 - val_loss: 1.3790 - val_acc: 0.5061\n",
            "Epoch 332/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2219 - acc: 0.5722 - val_loss: 1.3759 - val_acc: 0.5128\n",
            "Epoch 333/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2207 - acc: 0.5729 - val_loss: 1.3742 - val_acc: 0.5120\n",
            "Epoch 334/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2198 - acc: 0.5728 - val_loss: 1.3781 - val_acc: 0.5155\n",
            "Epoch 335/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2176 - acc: 0.5742 - val_loss: 1.3888 - val_acc: 0.5022\n",
            "Epoch 336/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2163 - acc: 0.5743 - val_loss: 1.3694 - val_acc: 0.5160\n",
            "Epoch 337/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2164 - acc: 0.5737 - val_loss: 1.3802 - val_acc: 0.5126\n",
            "Epoch 338/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2155 - acc: 0.5747 - val_loss: 1.3752 - val_acc: 0.5161\n",
            "Epoch 339/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2143 - acc: 0.5757 - val_loss: 1.3696 - val_acc: 0.5139\n",
            "Epoch 340/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2123 - acc: 0.5767 - val_loss: 1.3641 - val_acc: 0.5176\n",
            "Epoch 341/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2116 - acc: 0.5755 - val_loss: 1.3643 - val_acc: 0.5187\n",
            "Epoch 342/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2105 - acc: 0.5756 - val_loss: 1.3827 - val_acc: 0.5104\n",
            "Epoch 343/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2095 - acc: 0.5766 - val_loss: 1.3853 - val_acc: 0.5058\n",
            "Epoch 344/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2073 - acc: 0.5770 - val_loss: 1.3820 - val_acc: 0.5117\n",
            "Epoch 345/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2075 - acc: 0.5767 - val_loss: 1.3700 - val_acc: 0.5173\n",
            "Epoch 346/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2065 - acc: 0.5793 - val_loss: 1.3745 - val_acc: 0.5109\n",
            "Epoch 347/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2053 - acc: 0.5772 - val_loss: 1.4197 - val_acc: 0.5043\n",
            "Epoch 348/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2037 - acc: 0.5789 - val_loss: 1.3850 - val_acc: 0.5087\n",
            "Epoch 349/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2021 - acc: 0.5790 - val_loss: 1.3698 - val_acc: 0.5124\n",
            "Epoch 350/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2013 - acc: 0.5804 - val_loss: 1.3632 - val_acc: 0.5196\n",
            "Epoch 351/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2006 - acc: 0.5807 - val_loss: 1.3633 - val_acc: 0.5176\n",
            "Epoch 352/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1985 - acc: 0.5815 - val_loss: 1.3689 - val_acc: 0.5110\n",
            "Epoch 353/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1985 - acc: 0.5798 - val_loss: 1.3649 - val_acc: 0.5196\n",
            "Epoch 354/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1966 - acc: 0.5814 - val_loss: 1.3663 - val_acc: 0.5126\n",
            "Epoch 355/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1954 - acc: 0.5808 - val_loss: 1.3782 - val_acc: 0.5093\n",
            "Epoch 356/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1969 - acc: 0.5804 - val_loss: 1.3733 - val_acc: 0.5106\n",
            "Epoch 357/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1932 - acc: 0.5817 - val_loss: 1.3664 - val_acc: 0.5147\n",
            "Epoch 358/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1928 - acc: 0.5826 - val_loss: 1.3855 - val_acc: 0.5116\n",
            "Epoch 359/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1918 - acc: 0.5831 - val_loss: 1.3587 - val_acc: 0.5209\n",
            "Epoch 360/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1905 - acc: 0.5836 - val_loss: 1.3669 - val_acc: 0.5174\n",
            "Epoch 361/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1895 - acc: 0.5834 - val_loss: 1.3610 - val_acc: 0.5155\n",
            "Epoch 362/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1893 - acc: 0.5847 - val_loss: 1.3636 - val_acc: 0.5138\n",
            "Epoch 363/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1872 - acc: 0.5847 - val_loss: 1.3611 - val_acc: 0.5200\n",
            "Epoch 364/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1853 - acc: 0.5855 - val_loss: 1.3651 - val_acc: 0.5152\n",
            "Epoch 365/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1845 - acc: 0.5854 - val_loss: 1.3612 - val_acc: 0.5191\n",
            "Epoch 366/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1837 - acc: 0.5859 - val_loss: 1.3590 - val_acc: 0.5176\n",
            "Epoch 367/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1822 - acc: 0.5865 - val_loss: 1.3654 - val_acc: 0.5111\n",
            "Epoch 368/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1825 - acc: 0.5867 - val_loss: 1.3718 - val_acc: 0.5126\n",
            "Epoch 369/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1808 - acc: 0.5858 - val_loss: 1.3874 - val_acc: 0.5038\n",
            "Epoch 370/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1795 - acc: 0.5887 - val_loss: 1.3825 - val_acc: 0.5128\n",
            "Epoch 371/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1778 - acc: 0.5875 - val_loss: 1.3789 - val_acc: 0.5117\n",
            "Epoch 372/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1772 - acc: 0.5862 - val_loss: 1.3815 - val_acc: 0.5101\n",
            "Epoch 373/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1757 - acc: 0.5879 - val_loss: 1.3761 - val_acc: 0.5174\n",
            "Epoch 374/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1754 - acc: 0.5879 - val_loss: 1.4616 - val_acc: 0.4962\n",
            "Epoch 375/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1750 - acc: 0.5884 - val_loss: 1.3641 - val_acc: 0.5202\n",
            "Epoch 376/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1742 - acc: 0.5898 - val_loss: 1.3632 - val_acc: 0.5185\n",
            "Epoch 377/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1720 - acc: 0.5894 - val_loss: 1.3670 - val_acc: 0.5150\n",
            "Epoch 378/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1712 - acc: 0.5910 - val_loss: 1.3754 - val_acc: 0.5147\n",
            "Epoch 379/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1702 - acc: 0.5902 - val_loss: 1.3511 - val_acc: 0.5190\n",
            "Epoch 380/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1690 - acc: 0.5923 - val_loss: 1.3551 - val_acc: 0.5189\n",
            "Epoch 381/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1702 - acc: 0.5913 - val_loss: 1.3966 - val_acc: 0.5081\n",
            "Epoch 382/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1667 - acc: 0.5932 - val_loss: 1.3604 - val_acc: 0.5175\n",
            "Epoch 383/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1653 - acc: 0.5911 - val_loss: 1.3599 - val_acc: 0.5205\n",
            "Epoch 384/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1643 - acc: 0.5925 - val_loss: 1.3637 - val_acc: 0.5171\n",
            "Epoch 385/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1642 - acc: 0.5938 - val_loss: 1.3704 - val_acc: 0.5193\n",
            "Epoch 386/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1627 - acc: 0.5926 - val_loss: 1.3497 - val_acc: 0.5244\n",
            "Epoch 387/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1614 - acc: 0.5949 - val_loss: 1.3516 - val_acc: 0.5224\n",
            "Epoch 388/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1600 - acc: 0.5951 - val_loss: 1.3516 - val_acc: 0.5203\n",
            "Epoch 389/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1586 - acc: 0.5945 - val_loss: 1.3811 - val_acc: 0.5098\n",
            "Epoch 390/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1575 - acc: 0.5951 - val_loss: 1.3738 - val_acc: 0.5157\n",
            "Epoch 391/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1575 - acc: 0.5953 - val_loss: 1.3817 - val_acc: 0.5135\n",
            "Epoch 392/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1580 - acc: 0.5949 - val_loss: 1.3596 - val_acc: 0.5192\n",
            "Epoch 393/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1556 - acc: 0.5951 - val_loss: 1.3647 - val_acc: 0.5134\n",
            "Epoch 394/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1523 - acc: 0.5959 - val_loss: 1.3541 - val_acc: 0.5224\n",
            "Epoch 395/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1543 - acc: 0.5973 - val_loss: 1.3551 - val_acc: 0.5189\n",
            "Epoch 396/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1513 - acc: 0.5968 - val_loss: 1.3619 - val_acc: 0.5189\n",
            "Epoch 397/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1509 - acc: 0.5984 - val_loss: 1.3660 - val_acc: 0.5139\n",
            "Epoch 398/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1501 - acc: 0.5994 - val_loss: 1.3546 - val_acc: 0.5185\n",
            "Epoch 399/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1481 - acc: 0.5981 - val_loss: 1.3825 - val_acc: 0.5080\n",
            "Epoch 400/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1484 - acc: 0.5984 - val_loss: 1.3623 - val_acc: 0.5167\n",
            "Epoch 401/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1467 - acc: 0.5989 - val_loss: 1.3463 - val_acc: 0.5211\n",
            "Epoch 402/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1458 - acc: 0.6008 - val_loss: 1.3697 - val_acc: 0.5102\n",
            "Epoch 403/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1449 - acc: 0.5991 - val_loss: 1.3673 - val_acc: 0.5162\n",
            "Epoch 404/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1424 - acc: 0.6010 - val_loss: 1.3430 - val_acc: 0.5261\n",
            "Epoch 405/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1429 - acc: 0.6010 - val_loss: 1.3653 - val_acc: 0.5223\n",
            "Epoch 406/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1415 - acc: 0.6015 - val_loss: 1.3544 - val_acc: 0.5202\n",
            "Epoch 407/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1410 - acc: 0.6012 - val_loss: 1.4370 - val_acc: 0.5045\n",
            "Epoch 408/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1384 - acc: 0.6030 - val_loss: 1.3561 - val_acc: 0.5216\n",
            "Epoch 409/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.1373 - acc: 0.6030 - val_loss: 1.3754 - val_acc: 0.5168\n",
            "Epoch 410/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1379 - acc: 0.6033 - val_loss: 1.3863 - val_acc: 0.5152\n",
            "Epoch 411/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1364 - acc: 0.6041 - val_loss: 1.3486 - val_acc: 0.5221\n",
            "Epoch 412/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1346 - acc: 0.6046 - val_loss: 1.3601 - val_acc: 0.5229\n",
            "Epoch 413/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1347 - acc: 0.6042 - val_loss: 1.3571 - val_acc: 0.5243\n",
            "Epoch 414/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1333 - acc: 0.6031 - val_loss: 1.3822 - val_acc: 0.5113\n",
            "Epoch 415/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1320 - acc: 0.6040 - val_loss: 1.3909 - val_acc: 0.5116\n",
            "Epoch 416/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1309 - acc: 0.6043 - val_loss: 1.3601 - val_acc: 0.5208\n",
            "Epoch 417/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1290 - acc: 0.6059 - val_loss: 1.3613 - val_acc: 0.5239\n",
            "Epoch 418/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1300 - acc: 0.6049 - val_loss: 1.4221 - val_acc: 0.5046\n",
            "Epoch 419/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1285 - acc: 0.6059 - val_loss: 1.3931 - val_acc: 0.5125\n",
            "Epoch 420/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1274 - acc: 0.6058 - val_loss: 1.4021 - val_acc: 0.5102\n",
            "Epoch 421/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1262 - acc: 0.6070 - val_loss: 1.3503 - val_acc: 0.5249\n",
            "Epoch 422/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1250 - acc: 0.6070 - val_loss: 1.4012 - val_acc: 0.5111\n",
            "Epoch 423/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1231 - acc: 0.6077 - val_loss: 1.3460 - val_acc: 0.5261\n",
            "Epoch 424/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1219 - acc: 0.6077 - val_loss: 1.3811 - val_acc: 0.5164\n",
            "Epoch 425/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1215 - acc: 0.6087 - val_loss: 1.3532 - val_acc: 0.5201\n",
            "Epoch 426/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1199 - acc: 0.6091 - val_loss: 1.3743 - val_acc: 0.5143\n",
            "Epoch 427/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1206 - acc: 0.6092 - val_loss: 1.3460 - val_acc: 0.5226\n",
            "Epoch 428/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1195 - acc: 0.6093 - val_loss: 1.3546 - val_acc: 0.5210\n",
            "Epoch 429/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1151 - acc: 0.6112 - val_loss: 1.4403 - val_acc: 0.4978\n",
            "Epoch 430/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1162 - acc: 0.6107 - val_loss: 1.3974 - val_acc: 0.5122\n",
            "Epoch 431/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1162 - acc: 0.6087 - val_loss: 1.3894 - val_acc: 0.5107\n",
            "Epoch 432/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1143 - acc: 0.6115 - val_loss: 1.3673 - val_acc: 0.5209\n",
            "Epoch 433/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1157 - acc: 0.6097 - val_loss: 1.3676 - val_acc: 0.5170\n",
            "Epoch 434/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1114 - acc: 0.6108 - val_loss: 1.3428 - val_acc: 0.5291\n",
            "Epoch 435/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1101 - acc: 0.6122 - val_loss: 1.3411 - val_acc: 0.5250\n",
            "Epoch 436/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1088 - acc: 0.6133 - val_loss: 1.3525 - val_acc: 0.5267\n",
            "Epoch 437/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.1095 - acc: 0.6127 - val_loss: 1.3921 - val_acc: 0.5192\n",
            "Epoch 438/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1056 - acc: 0.6139 - val_loss: 1.3521 - val_acc: 0.5243\n",
            "Epoch 439/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1076 - acc: 0.6118 - val_loss: 1.3870 - val_acc: 0.5053\n",
            "Epoch 440/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1053 - acc: 0.6141 - val_loss: 1.3787 - val_acc: 0.5100\n",
            "Epoch 441/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1064 - acc: 0.6135 - val_loss: 1.3388 - val_acc: 0.5271\n",
            "Epoch 442/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1054 - acc: 0.6150 - val_loss: 1.3405 - val_acc: 0.5290\n",
            "Epoch 443/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1029 - acc: 0.6148 - val_loss: 1.3672 - val_acc: 0.5196\n",
            "Epoch 444/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1036 - acc: 0.6134 - val_loss: 1.3730 - val_acc: 0.5164\n",
            "Epoch 445/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1016 - acc: 0.6154 - val_loss: 1.3654 - val_acc: 0.5213\n",
            "Epoch 446/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1025 - acc: 0.6168 - val_loss: 1.3652 - val_acc: 0.5208\n",
            "Epoch 447/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0982 - acc: 0.6165 - val_loss: 1.3549 - val_acc: 0.5205\n",
            "Epoch 448/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1013 - acc: 0.6154 - val_loss: 1.3666 - val_acc: 0.5196\n",
            "Epoch 449/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.0981 - acc: 0.6163 - val_loss: 1.3368 - val_acc: 0.5282\n",
            "Epoch 450/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.0965 - acc: 0.6178 - val_loss: 1.3749 - val_acc: 0.5162\n",
            "Epoch 451/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0953 - acc: 0.6186 - val_loss: 1.3488 - val_acc: 0.5240\n",
            "Epoch 452/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.0932 - acc: 0.6206 - val_loss: 1.3547 - val_acc: 0.5232\n",
            "Epoch 453/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0915 - acc: 0.6200 - val_loss: 1.4925 - val_acc: 0.4881\n",
            "Epoch 454/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0923 - acc: 0.6205 - val_loss: 1.3654 - val_acc: 0.5214\n",
            "Epoch 455/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0927 - acc: 0.6183 - val_loss: 1.3601 - val_acc: 0.5233\n",
            "Epoch 456/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0910 - acc: 0.6194 - val_loss: 1.3768 - val_acc: 0.5156\n",
            "Epoch 457/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0904 - acc: 0.6202 - val_loss: 1.3398 - val_acc: 0.5260\n",
            "Epoch 458/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0853 - acc: 0.6215 - val_loss: 1.3406 - val_acc: 0.5276\n",
            "Epoch 459/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0863 - acc: 0.6210 - val_loss: 1.3698 - val_acc: 0.5177\n",
            "Epoch 460/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0866 - acc: 0.6204 - val_loss: 1.3474 - val_acc: 0.5286\n",
            "Epoch 461/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0867 - acc: 0.6218 - val_loss: 1.3645 - val_acc: 0.5189\n",
            "Epoch 462/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0847 - acc: 0.6221 - val_loss: 1.3400 - val_acc: 0.5323\n",
            "Epoch 463/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0852 - acc: 0.6212 - val_loss: 1.3514 - val_acc: 0.5254\n",
            "Epoch 464/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0810 - acc: 0.6232 - val_loss: 1.3544 - val_acc: 0.5237\n",
            "Epoch 465/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.0829 - acc: 0.6220 - val_loss: 1.3879 - val_acc: 0.5177\n",
            "Epoch 466/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0816 - acc: 0.6222 - val_loss: 1.3686 - val_acc: 0.5198\n",
            "Epoch 467/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0798 - acc: 0.6243 - val_loss: 1.3673 - val_acc: 0.5230\n",
            "Epoch 468/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0797 - acc: 0.6255 - val_loss: 1.3779 - val_acc: 0.5204\n",
            "Epoch 469/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0800 - acc: 0.6248 - val_loss: 1.3517 - val_acc: 0.5225\n",
            "Epoch 470/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0758 - acc: 0.6260 - val_loss: 1.3374 - val_acc: 0.5275\n",
            "Epoch 471/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0757 - acc: 0.6245 - val_loss: 1.3428 - val_acc: 0.5261\n",
            "Epoch 472/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0724 - acc: 0.6256 - val_loss: 1.3764 - val_acc: 0.5139\n",
            "Epoch 473/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0720 - acc: 0.6254 - val_loss: 1.3769 - val_acc: 0.5194\n",
            "Epoch 474/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0709 - acc: 0.6252 - val_loss: 1.3536 - val_acc: 0.5282\n",
            "Epoch 475/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0703 - acc: 0.6263 - val_loss: 1.3602 - val_acc: 0.5215\n",
            "Epoch 476/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0691 - acc: 0.6281 - val_loss: 1.3401 - val_acc: 0.5312\n",
            "Epoch 477/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0682 - acc: 0.6287 - val_loss: 1.3958 - val_acc: 0.5159\n",
            "Epoch 478/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.0681 - acc: 0.6283 - val_loss: 1.4226 - val_acc: 0.5090\n",
            "Epoch 479/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0680 - acc: 0.6278 - val_loss: 1.3727 - val_acc: 0.5180\n",
            "Epoch 480/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0658 - acc: 0.6288 - val_loss: 1.4133 - val_acc: 0.5138\n",
            "Epoch 481/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0659 - acc: 0.6293 - val_loss: 1.3303 - val_acc: 0.5319\n",
            "Epoch 482/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.0656 - acc: 0.6281 - val_loss: 1.3438 - val_acc: 0.5281\n",
            "Epoch 483/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0707 - acc: 0.6266 - val_loss: 1.3871 - val_acc: 0.5126\n",
            "Epoch 484/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.0642 - acc: 0.6306 - val_loss: 1.3507 - val_acc: 0.5299\n",
            "Epoch 485/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0619 - acc: 0.6305 - val_loss: 1.3382 - val_acc: 0.5245\n",
            "Epoch 486/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0592 - acc: 0.6309 - val_loss: 1.3473 - val_acc: 0.5241\n",
            "Epoch 487/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0600 - acc: 0.6309 - val_loss: 1.4057 - val_acc: 0.5097\n",
            "Epoch 488/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0592 - acc: 0.6310 - val_loss: 1.3350 - val_acc: 0.5338\n",
            "Epoch 489/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0580 - acc: 0.6308 - val_loss: 1.3782 - val_acc: 0.5240\n",
            "Epoch 490/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0557 - acc: 0.6333 - val_loss: 1.3346 - val_acc: 0.5314\n",
            "Epoch 491/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0548 - acc: 0.6319 - val_loss: 1.3787 - val_acc: 0.5189\n",
            "Epoch 492/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0570 - acc: 0.6324 - val_loss: 1.4123 - val_acc: 0.5069\n",
            "Epoch 493/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.0562 - acc: 0.6322 - val_loss: 1.3420 - val_acc: 0.5272\n",
            "Epoch 494/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0585 - acc: 0.6299 - val_loss: 1.3669 - val_acc: 0.5227\n",
            "Epoch 495/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0562 - acc: 0.6327 - val_loss: 1.3412 - val_acc: 0.5317\n",
            "Epoch 496/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0507 - acc: 0.6350 - val_loss: 1.3410 - val_acc: 0.5294\n",
            "Epoch 497/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0495 - acc: 0.6337 - val_loss: 1.3593 - val_acc: 0.5275\n",
            "Epoch 498/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0478 - acc: 0.6337 - val_loss: 1.3383 - val_acc: 0.5297\n",
            "Epoch 499/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0536 - acc: 0.6326 - val_loss: 1.3434 - val_acc: 0.5312\n",
            "Epoch 500/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0503 - acc: 0.6347 - val_loss: 1.3522 - val_acc: 0.5246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f91ead16668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "WPbPijCN3A2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "fef56ae6-750b-48fb-ad61-7f3ae5b15b86"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\"\"\"\n",
        "Get the training loss / validation loss / training accuracy / validation accuracy and plot them\n",
        "\"\"\"\n",
        "\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "\n",
        "train_acc = model.history.history[\"acc\"]\n",
        "valid_acc = model.history.history[\"val_acc\"]\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd6WU8kD/D+I/Carw8BNKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xlc1VX+x/HXYQdBZBFcQMEdQXHB\nrdTMpTFLM820zWpKm2ydpmlsasxq5jdNU00zk9OM7dpiaotmWmZpm5m7uO8ooCIIssjOPb8/zoV7\nQRBS4HIvn+fjwePe7/d77veeL+L7nnu+53u+SmuNEEII1+Lm6AoIIYSofxLuQgjhgiTchRDCBUm4\nCyGEC5JwF0IIFyThLoQQLkjCXQghXJCEu3A6Sql1SqkspZS3o+siRFMl4S6cilIqChgGaGBCI76v\nR2O9lxD1QcJdOJvpwAbgbeD28pVKKV+l1ItKqWNKqWyl1A9KKV/rtqFKqfVKqbNKqWSl1B3W9euU\nUnfb7eMOpdQPdstaKXWfUuogcNC67p/WfeQopbYopYbZlXdXSv1RKXVYKZVr3R6plJqnlHrR/iCU\nUsuVUr9tiF+QECDhLpzPdOA968+vlFLh1vUvAP2By4Bg4DHAopTqCKwC/g20BvoA23/B+00EBgE9\nrcubrPsIBt4HliilfKzbHgFuAsYBLYFfA/nAO8BNSik3AKVUKDDa+nohGoSEu3AaSqmhQEdgsdZ6\nC3AYuNkamr8GHtJap2qty7TW67XWRcDNwBqt9Qda6xKt9Rmt9S8J979qrTO11gUAWut3rfso1Vq/\nCHgD3a1l7wae1Frv18YOa9mNQDYwylpuGrBOa512ib8SIWok4S6cye3Aaq11hnX5feu6UMAHE/ZV\nRdawvq6S7ReUUo8qpfZau37OAoHW96/tvd4BbrU+vxVYeAl1EqJWcpJIOAVr//mNgLtS6pR1tTfQ\nCmgLFAKdgR1VXpoMDKxht+cAP7vlNtWUqZg21dq//himBb5ba21RSmUByu69OgO7qtnPu8AupVQ8\nEAN8WkOdhKgX0nIXzmIiUIbp++5j/YkBvsf0w78JvKSUamc9sTnEOlTyPWC0UupGpZSHUipEKdXH\nus/twCSllJ9SqgtwVy11CABKgXTAQyk1B9O3Xu514FmlVFdl9FZKhQBorVMw/fULgY/Ku3mEaCgS\n7sJZ3A68pbU+rrU+Vf4DvALcAswGdmICNBP4G+CmtT6OOcH5O+v67UC8dZ//AIqBNEy3yXu11OFL\n4AvgAHAM823BvtvmJWAxsBrIAd4AfO22vwP0QrpkRCNQcrMOIRqHUmo4pnumo5b/eKKBSctdiEag\nlPIEHgJel2AXjUHCXYgGppSKAc5iTvy+7ODqiGZCumWEEMIFSctdCCFckMPGuYeGhuqoqChHvb0Q\nQjilLVu2ZGitW9dWzmHhHhUVxebNmx319kII4ZSUUsfqUk66ZYQQwgVJuAshhAuScBdCCBfUpCYO\nKykpISUlhcLCQkdXRdTCx8eHiIgIPD09HV0VIUQ1mlS4p6SkEBAQQFRUFEqp2l8gHEJrzZkzZ0hJ\nSSE6OtrR1RFCVKNJdcsUFhYSEhIiwd7EKaUICQmRb1hCNGFNKtwBCXYnIf9OQjRtTS7chRDC1SRn\n5rNseypaaz7YeJycwpIGf08Jdztnz57lP//5z0W9dty4cZw9e7aeaySEcEaZ54p5dMkOXv/+CNuT\nzzJjwWYeWrSd6MdX8vjHO1m08XiD16FJnVB1tPJwnzVr1nnbSktL8fCo+de1cuXKhqzaRdNao7XG\nzU0+x4VoKFprViSe5OejZ0jNKmDDkUwKSsoqlYmPbIXFovHzcufOyxt+IIL8j7cze/ZsDh8+TJ8+\nffj973/PunXrGDZsGBMmTKBnz54ATJw4kf79+xMbG8v8+fMrXhsVFUVGRgZJSUnExMQwY8YMYmNj\nueqqqygoOP+Oap999hmDBg2ib9++jB49mrS0NADy8vK488476dWrF7179+ajjz4C4IsvvqBfv37E\nx8czatQoAObOncsLL7xQsc+4uDiSkpJISkqie/fuTJ8+nbi4OJKTk7n33ntJSEggNjaWp556quI1\nmzZt4rLLLiM+Pp6BAweSm5vL8OHD2b59e0WZoUOHsmNH1VuTCtF8bUrK5P73t/KnT3cx6sV1XPvv\nH/jdkh28u+E4p3OL6BLmz22DO/La9AQCfDxoF+jDR78ZwmcPDGXRzMF4ujd89DbZlvvTn+1mz4mc\net1nz3YteWp8bI3bn3vuOXbt2lURbOvWrWPr1q3s2rWrYsjfm2++SXBwMAUFBQwYMIDJkycTEhJS\naT8HDx7kgw8+4LXXXuPGG2/ko48+4tZbb61UZujQoWzYsAGlFK+//jrPP/88L774Is8++yyBgYHs\n3LkTgKysLNLT05kxYwbfffcd0dHRZGZm1nqsBw8e5J133mHw4MEA/OUvfyE4OJiysjJGjRpFYmIi\nPXr0YOrUqXz44YcMGDCAnJwcfH19ueuuu3j77bd5+eWXOXDgAIWFhcTHx9fyjkK4ptM5hWxMyiQt\np4iOwX5k5Rfz1PLdlFk0RaUWWvl5cjbf9KEv/c0QEqKCK71+w+Oj0ICHNdAbazBCkw33pmLgwIGV\nxnL/61//4pNPPgEgOTmZgwcPnhfu0dHR9Olj7sHcv39/kpKSzttvSkoKU6dO5eTJkxQXF1e8x5o1\na1i0aFFFuaCgID777DOGDx9eUSY4OPi8/VXVsWPHimAHWLx4MfPnz6e0tJSTJ0+yZ88elFK0bduW\nAQMGANCypbnX85QpU3j22Wf5+9//zptvvskdd9xR6/sJ4WoOpOWigJte+5mMvKJK2yKCfFn6m8vw\n8XTD39uDHSnZ/Hgog34dgs7bTwtvx8Rskw33C7WwG1OLFi0qnq9bt441a9bw008/4efnx4gRI6od\n6+3t7V3x3N3dvdpumQceeIBHHnmECRMmsG7dOubOnfuL6+bh4YHFYqlYtq+Lfb2PHj3KCy+8wKZN\nmwgKCuKOO+644Bh1Pz8/xowZw7Jly1i8eDFbtmz5xXUToqnTWnPmXDGe7m4E+nryxa5TpGTlc+h0\nHp/tOMG5YtNn7uflzoMju+Dl4UZQCy+iQ1oQ2z6QQF/b1dn9OwbRv+P5we5ITTbcHSEgIIDc3Nwa\nt2dnZxMUFISfnx/79u1jw4YNF/1e2dnZtG/fHoB33nmnYv2YMWOYN28eL79s7saWlZXF4MGDmTVr\nFkePHq3olgkODiYqKooVK1YAsHXrVo4ePVrte+Xk5NCiRQsCAwNJS0tj1apVjBgxgu7du3Py5Ek2\nbdrEgAEDyM3NxdfXFw8PD+6++27Gjx/PsGHDCApqWn+0QtSHf39ziJe+OgBAQscgNh/LqtgW4GOi\ncXRMOLdf1pFhXWudPr3JkXC3ExISwuWXX05cXBxXX30111xzTaXtY8eO5b///S8xMTF07969UrfH\nLzV37lymTJlCUFAQI0eOrAjmJ598kvvuu4+4uDjc3d156qmnmDRpEvPnz2fSpElYLBbCwsL46quv\nmDx5MgsWLCA2NpZBgwbRrVu3at8rPj6evn370qNHDyIjI7n88ssB8PLy4sMPP+SBBx6goKAAX19f\n1qxZg7+/P/3796dly5bceeedF32MQjQlFovms8QT+Hl58P3BdBb8dIxQf29yCkvYfCyLe0d0ZkJ8\nO05mF3Bl9zDKLLqin9wZOeweqgkJCbrqzTr27t1LTEyMQ+ojKjtx4gQjRoxg3759NQ6jlH8v0ZSl\n5xZRXGZhzZ40Nhw5w75TuRzNOFex/c7Lo3j86hgKS8s4fiafuPaBDqxt3SmltmitE2orJy13cZ4F\nCxbwxBNP8NJLL8n4eOEULBaNBvKLS0lMyeahRdvPOwkKMDUhkh5tA/D39uCG/hEopfDycHOaYP8l\nJNzFeaZPn8706dMdXQ0hanU6p5CPt6Xy0uoDFJfZBhd4e9gaJRP7tOOxsT3YeDSTsXFt8PF0d0RV\nG52EuxDCaWit2Xcql58On2HZjhPsSD5/yo/LOofw6q39CfT1JLugpGJUy8S+7Ru7ug5Vp3BXSo0F\n/gm4A69rrZ+rpsyNwFxAAzu01jfXYz2FEM3MuaJSwIwTX/hTEmv3p3PmXHFFoIcFePPHcT2IDvVn\nYHQwH29NYVyvtoQFeFdcKGQ/XLG5qTXclVLuwDxgDJACbFJKLdda77Er0xV4HLhca52llAprqAoL\nIVxXcamFT7elsjM1mw83J1NmnYslt9AEfZuWPtwzvBM39I+ga3hApdc2xnwtzqQuLfeBwCGt9REA\npdQi4Dpgj12ZGcA8rXUWgNb6dH1XVAjhmtYfziAlq4Btx7P4PPEkOYWluCmYEN+O/OIydqZmc/+V\nXfhVbBsig/1wd5N7CdRFXcK9PZBst5wCDKpSphuAUupHTNfNXK31F/VSwybO39+fvLw8Tpw4wYMP\nPsjSpUvPKzNixAheeOEFEhJqHb0kRLOwbHsqb/6YRELHIN74wXbxXffwAG4ZHMZvR3fDy3pSVGst\nN4e5CPV1QtUD6AqMACKA75RSvbTWlc52KKVmAjMBOnToUE9v3TS0a9eu2mBvCmqbrliIhqa1xqIh\nMeUsv1uygyPpZrz5juSzBHh7MKhTMHMnxBIR5HfeayXYL05dBjGnApF2yxHWdfZSgOVa6xKt9VHg\nACbsK9Faz9daJ2itE1q3bnqX886ePZt58+ZVLJdPqZuXl8eoUaPo168fvXr1YtmyZee9Nikpibi4\nOAAKCgqYNm0aMTExXH/99dXOLQPwzDPPMGDAAOLi4pg5cyblF5QdOnSI0aNHEx8fT79+/Th8+DAA\nf/vb3+jVqxfx8fHMnj0bMN8Kyi8Gy8jIICoqCoC3336bCRMmMHLkSEaNGnXBY1iwYAG9e/cmPj6e\n2267jdzcXKKjoykpMTPd5eTkVFoW4kIKS8ooKbPw2Y4TTH51PQl//opec1fTc84XTHp1PcmZ+VzX\npx3b54zhu99fSeLcq3j99gHVBru4eHVpzm0CuiqlojGhPg2oOhLmU+Am4C2lVCimm+bIJdVs1Ww4\ntfOSdnGeNr3g6vMG+lSYOnUqDz/8MPfddx9gZlL88ssv8fHx4ZNPPqFly5ZkZGQwePBgJkyYUGOL\n4tVXX8XPz4+9e/eSmJhIv379qi13//33M2fOHABuu+02VqxYwfjx47nllluYPXs2119/PYWFhVgs\nFlatWsWyZcv4+eef8fPzq9O0v1u3biUxMZHg4GBKS0urPYY9e/bw5z//mfXr1xMaGkpmZiYBAQGM\nGDGCzz//nIkTJ7Jo0SImTZqEp2fzHXkgLsxiMUMUZ3+cSGJKdqVtQzqF0K6VLwE+HrTy8+SOy6Jo\n5ecFUPEo6l+t4a61LlVK3Q98ielPf1NrvVsp9QywWWu93LrtKqXUHqAM+L3W+kxDVrwh9O3bl9On\nT3PixAnS09MJCgoiMjKSkpIS/vjHP/Ldd9/h5uZGamoqaWlptGnTptr9fPfddzz44IMA9O7dm969\ne1dbbu3atTz//PPk5+eTmZlJbGwsI0aMIDU1leuvvx4AHx8fwEwFfOedd+LnZ1o3dZn2d8yYMRXl\ntNbVHsM333zDlClTCA0NrbTfu+++m+eff56JEyfy1ltv8dprr9X11yiagdzCEgJ8zIf9yp0neemr\nAxw6nVepzPBurbmqZzi3Du7oiCo2e3XqiNVarwRWVlk3x+65Bh6x/tSPC7SwG9KUKVNYunQpp06d\nYurUqQC89957pKens2XLFjw9PYmKirrglLl1UVhYyKxZs9i8eTORkZHMnTv3ovZpP+1v1dfbT/v7\nS4/h8ssvJykpiXXr1lFWVlbR5SSat5PZBby74RivrjvMwOhgMs8VcyDNhHqn0BY8NLorQzqHkFtY\nSufW/g6ubfMmE4dUMXXqVBYtWsTSpUuZMmUKYKbnDQsLw9PTk7Vr13Ls2LEL7mP48OG8//77AOza\ntYvExMTzypQHa2hoKHl5eRUnYwMCAoiIiODTTz8FoKioiPz8fMaMGcNbb71Ffn4+QEW3TFRUVMV8\n6xc6oVvTMYwcOZIlS5Zw5syZSvsFMw3BzTffLDNDNmPl487ve38r4/75PUP++g3z1h5GQ8V9Qv8w\ntgcH/3I13zw6guv6tCcswEeCvQmQIRRVxMbGkpubS/v27Wnbti0At9xyC+PHj6dXr14kJCTQo0eP\nC+7j3nvv5c477yQmJoaYmBj69+9/XplWrVoxY8YM4uLiaNOmTcXdkAAWLlzIPffcw5w5c/D09GTJ\nkiWMHTuW7du3k5CQgJeXF+PGjeP//u//ePTRR7nxxhuZP3/+eVMU26vpGGJjY3niiSe44oorcHd3\np2/fvrz99tsVr3nyySe56aabfumvUTi5Hw5m8NaPR1m7/zQWDQHeHsS2b8kjY7qRX1zGtb3bcjg9\nj1Ex4fg76E5D4sJkyl9Ro6VLl7Js2TIWLlxY7Xb593Ju5ePHd6Vm8+q3h/k88SRguleOZJwjvKU3\nA6KCGd6tNRPi2zWbCbeaOpnyV1ySBx54gFWrVrFy5craCwunk3WumEmvrudoxjncFHhYp3Zu6eNB\nblEpNyZE8Mx1cRLoTkzCXVTr3//+t6OrIOpRdkEJT3+2m8xzxXi4ubFmb1rFtl/FtuGp8bF4e7ih\nlAxPdBVNLtzlUmPn4KjuPFG7rHPFKAV5RaUs+OkY6w9nkJSRT551lkVvDzduGhhJ9/AAuoUHMKRz\niPyfc0FNKtx9fHw4c+YMISHyx9aUaa05c+ZMxRh84Xg7U7LZlpzFxqOZrEg8ibubosxiPoA7tW5B\n5zB/nhrfk06hLXB3UxVj1IXralLhHhERQUpKCunp6Y6uiqiFj48PERERjq5Gs5WdX8L6wxl4ebjR\nJcyf8a/8AFAxY+KQTiEMjA4mISqIIZ2ksdQcNalw9/T0JDpa5mQWoibr9p/m88STLNmSct62Wwd3\n4A9je+CmFC1keGKzJ38BQjRxq6yX93cLD+DznScr1v/f9b3oEubPlmNZ9GgbwJXd5R45wkbCXYgm\nRGvNmr2n2Xj0DG5uinX70tmflgvAibMF9GgTQJCfFy9P60N4S3POY2B07fMMieZHwl0IB0vPLWLV\nrpN8vDWVoxnnyC6wTa3co00AD4/uyp2XRzfr+4GKX07CXYhGtPtENst3nKCguAw/Lw/2ncrhh4MZ\nlFrvFToqJpy+ka0YH9+OxJSzjOgeJreVExdFwl2IRpBbWMI3+07zxCe7KCgpqxim2Ll1C+4aGs3w\nbq3pEOxHZLDthhWjYsIdVV3hAiTchWgAxaUWVu85xansQjYnZfHV3jTKLJrwlt6semgYS7ekMKhT\nMJd1DnV0VYWLknAXoh6dzC7gzyv28t3BdHILzRWhAd4e9I1sxa+HRjM6JhwvDzd+O6abg2sqXJ2E\nuxAX6XROIS9/fZDUrAIyzxWzPy2X4lILvp7ujO4Zzq9iwxnWtTUtfTzkIiLR6CTchfgFthzLZMOR\nTNJyCvlkWypFJRZi2gbg5+XObYM7EuTnybW92xEV2qL2nQnRgCTchahFRl4RR9LPcTg9jxdX7ycj\nrxgwJ0P/Oa0vce0DHVxDIc4n4S5ENc4VlbIi8QSbk7JYtuMExaXmPrXhLb35+w29Sc4q4IGRXfB0\nlztViqZJwl0I4ExeESt3niS7oIQXVh+otC06tAWzr+5B9/AAOob4Sf+5cAoS7qJZe/vHoyRnFfDd\ngXQOns6rWO/t4cZT42OJDPala1gAbQJlemPhXCTcRbPz5e5TnM0vZmdqNu9uOA6AUvD7X3Un1N+L\nfh2C6BjSAi8P6XIRzkvCXbi8MovmXHEpKxNPsnDDMXafyKnYNrlfBKNjwriie2v8vOS/gwC0hmM/\nQsfLzad+bUoKwVIC3gFmeddHsPTX8Idj4NvKrCstBo/GvX2h/DULl2SxaN5an8Sr6w6TkVcEmP+n\ngb6eDOkUwhPXxBAZ5Eegn0zGJapI/BA+uQcmvQa9b6y+zNr/A0sZjPoTvDvJfBg8vBO8/GHDf02Z\nv3WEe74H/3D4Zzxc/Ryk7QF3T/jVXxr8MCTchUvQWnPodB6RwX78fDSTT7el8sm21IrtU/pHYNEw\nZ3xPmV3RlZ3YBh/eBnethpbtzLrtH8DWBXD7Z+DuAWWlsHE+9L8DvGxz+ZCbBimbTLADHN9gC3et\nITsFWkXCzqXw7d/M+lF/MsEO8HIv8PSDTiNs+9y2EKKvgNIC+Owh2/oxz4Jbw3b7SbgLp6a1Zu/J\nXB5ZvJ19p3Ir3Tv0rqHRXNUznAFRwbjJzIpN29Hv4exx6HtL7WXLSmH9vyBuEgRFVd62dSFkJ8NL\nMXD3N9C6O3z6G7Mt+zgEdzIt8y8fh6IcGDHbbDuXAS9WmRIi96TdfhfAZw/CNS/C57+rXK5Fazhn\nvTVoST74Btm2Hf7GfJBUdeYQtG7YKSgk3IVT2ncqh1U7T/HK2kMVYQ5wWecQJvVrT0LH4EozLAoH\n2PgaJP0AN7wJbu4XLvvOteax+9XgZ735SPp+E6TjXoD0fWAphRahsOA6sz1xMcz6CcpKbP3Znr62\nfb4+Eq580rZ85ogJ99wTZnndXyEwArqMgW+eOb9OR741dbCUwp5lZt2aKuXKSkyr3t729+ze85Dt\n+e8OQN4p+N9wSN0i4S4EQEpWPvtP5bIpKYvvD6ZXnBT19/ZgTM9wbh3ckS5h/tLlUp+SN0LbPrWf\nCNS68olHiwUKsmDT6yaU1/eFoQ+bbcvuh7w0uGWJWc7PhBNbba/d9AYUZUOnK01fNsCBVbBmrnk+\n6De2sllJ8NWfYOPr8OA28PCGg1+Zfu9i67DWtX+2ld/9CeSkQMZB27pl99V8XJZS+OAmyDxsW1eU\nXbnMuXRzrHUREG4+nAbPgtCGnzhO6aqfOo0kISFBb9682SHvLZzL/lO5TJ3/E2fzS/BwU/Tt0Iqx\ncW0Z0b01nUJbyEVFdaW1aUlHDABPu3H7+z433Qeh3U0/8IC7ITsV/tETYq+H8Fg4uAZ63QD97zT9\n1uWO/wxvjYVblkLxOcg5YQJ0/b/Ndu+WUFoIjx6E3R/Dit+a9de8BJED4eOZcHrPhesd3NkWsINn\nwYb/nF/myifh6LeQ9D20T4DUesiWyEGQ/LNtued1thZ8uenLYcEE23J4HKTtMr/jlu1s5R9KhKCO\nl14nQCm1RWudUFs5abmLJmnhT0ks3ZpKm5befLk7DYAZw6KZNaILQS0ad0iZ08tNA10G379oWtNX\n/RkCIyHjAFzxGKyabfqjyw24GzL2m+e7PzE/AMkbTD/0qDlmef8X8OGtoC22VnZVV/wBVj9hTk6W\nBzvA54+cX7bjUDj2g225TS84d8YW7MrNvFd1CjJNVweY8jcuhMW32bYHd4LMIxAzAQLaVN8Pbm/A\nDCgpMOE+8knofg0c/8mEtacf3PYpvHlV5WAHCOtpwr20EFpGmHWBHeot2H8JCXfRJKTnFnEqu5Bt\nyVnsPZnDBxuTATjk5c49wzsxqV8E3dsEOLiWDcRSZkZcRA2r27hqMP3BJ7bCkPvh3cmm28PNw/RD\nX/ag6c89uAben3J+IKbtht2fwqmdcPnDUFZcefuZw7D4jurfd99KW7h/MLXm+rVoDcMehejh55cd\neA9s/N/5r+kwuHK4t+oI7t62PnJtMSNWqlOYY97z7DGY8ArEXAtxk82YczAfaItuhsseMN8YMg7C\nkbVV6hwGI/4APa+HFiHmvdrGmw87NzfTDQTmgyKghrtkhfeEnZix74HtzTpfx0wsJ+EuHOp0biGL\nNibz6rrDFJSUAeDj6ca0AZE8OzEODzfl2t0uKZvho7sh6yiMftqEzzd/NoE7/FHISzet6sBI0z88\n6Dew/EEoOWdeX94XrS3gEwj7VoC7F3Qba4K9KncvSN1qWreWUhNweacql/nwNlvf8pVPmn7r6OEm\nPHd9BIunA1X+TXpeBwVnTdcIwM2LoX0/01VTVe8bqw/3rmPg+xfM86G/hZ4TzXKqXZl9K2zPf73a\ntJ7BdPmU5JsPlBjryVlf64lZL3/ocQ08ngre/mbdTYtMF857N5jlkX8y9WrVwbb/wAgYNNO2XD4y\np9900xqvTusY81iSDy3Lwz2o+rINTMJdNLrTOYX8Z91hVu8+xencIkotmj6RrfDzcueuodEM7RqK\nt0ctoyucxa6PTEt4+O9trfJNr8OORaaf+t1JUGgN0jVPmW6Pn60Xwfz0yvn7yzhoC3Z7Sd+Dn/WW\nfalbTAvWXpvecOM78PP/bPsH+PZ58xjazXTTAJzebR59g80HTI9rTIv00BpzPFX7nQFuXGAe51pb\nqSGdzaOX3bz205ebY41IMH3wL3StvI9Wdl0Xo+dWXhcYaYY42uswCOZmwxu/Ml1GUDmcy0fdlIdr\nebCDOedQHr5gjrFVDYFdLrwnPLzLhL59g2PKO2bdlregTZxZV5Jv1gH4tLrwfhuIhLtoNMfOnOPl\nNQdZtt00xfp3DGJMz3CmXxZF59b+tby6iSvKhdxTZoRJi1DT0v3hZfj2ObN93wrztd7NA/LPmHXr\n/2W+vpcLaGcLXvsRHwAoCGhr66KYtQH+M7hyHfIzzGPaLtMv3G0sHPjCrLvtE1Ov9nbn4XyDzInH\nwA5w99emjimbYfMbZvhipytNiIX3NOU7XWkuyS+/aOdCfOy6IqKGmeVOV9jW+YfZng+eZfqqW1Rz\nP9mhj5jXg61rZ/hj0H2s3Xu1tD3vcU3l44Oaw9V+2KT98wtpFWl7HjHAXPTUbaz5sIhIMEMjwXwD\nc4aWu1JqLPBPwB14XWv9XJXtdwB/x/YF6hWt9ev1WE/hpE6cLeCdn5L4ZGsqp3OL8PU0dyxyykD/\n8gkIi4G+t5r/xOv/bb6qd7zcdB9c6CTdyR3nr0vZbMK+rAja9TPdEuVXPvoG28I9chBM+wDWzIFt\n75rRI2Ex5vL4j2eYMlHDTOu950TY86m5QKfzSFu4l3dRdBlle/8OQ2D/Soi73gRkn5sh7gYY9jtb\nf7E9N3fTffGWNVinL7ONOS836bXKF/8A3LGCal37D/NBN/z31W8H0/fdfazt99ciDEY+UblMeTCP\neLzyB0RJvnmM6F/9vj3troNqHQFKAAAca0lEQVTwvIg7Z92yxJyktR955O5pvk2AOZfi3bLyN4RG\nVGu4K6XcgXnAGCAF2KSUWq61rjp+6UOt9f0NUEfhZL7Zl8bq3Wmkni1gR/JZcgpL6RTagkn9Irih\nfwRdwppgqGclmRNoPoGw+HZzpWTL9qYl6B1gRoyUd5N0GwunEuHrp81ycGfbiT77YXtVTX7D7P+9\nGyAo2tY/PeR+E3Bnj9vC/apnYMkd5nnHy0zIdRltwr08PHvfaAv3IfebcO9/h/nAyEk1JxRXPWa2\nl1/q7hdsWr6h3Uxf/v6VEGs30sXDq/pgL9e6u3n0Da7cOi9X01ws1Un4dd3Lln84xU48f1up9YSw\nf5WTnF3GwNfPwKB7q9+nfWvd6yIuePMNgvY1fHCA+TCcue78ejWSurTcBwKHtNZHAJRSi4DrgFoG\np4rmxGLRvPvzMTYcOcPKneYEXdcwf4Z1bc0NCREMig52zKyLiUvMf7I4uwDLOAQf3QXT3jdBVpht\nJnay97X1SsToK0yQ21+o8tlDJmjLlYd539vM0L+X48x/+vKheeV6WU/e/SkDtrwNKx81y51HmtkD\ny8MycpAZX959HHz3AlxmbTN1vcq2vVzUMDOfSvexMGMttOsLna+88O+kvOVbmG1OALbrc+Hy9vyC\nYdRT5luGVwN8SD+wtfouklaR8JsfbCcs7ZUWmMeqIdq2t60VXR379/GoY7fML1V+7sEB6vK/rT1g\nfyYjBRhUTbnJSqnhwAHgt1rr5GrKCBdSWmbhuVX7OJ1bxPIdpi840NeTu4ZG89jY7o4/KVpWCh/f\nbZ6H9YSwHmZ44HuTzbqN82HM05C8qeZ9lLeuwXQ5nNxhWvDlozYC2tn6wb1bmhD63X4TNCe2mg+F\ndydX3qe7J7TuYVsOtPbjKgW/Pwwe1q/5Ht6VuyC8WsB9myr3V09fDlgvRGzf7/z6P5RY89hwn0Do\nMa7mY6/JMOsY9bpemflLXCgM2/Sqfn2JNdyr+yZxIe52VzM38CRejlBfTanPgA+01kVKqXuAd4CR\nVQsppWYCMwE6dKjlzLRokrTWfLgpmS3HsjiZXcgPh8xJvKFdQhkf35YbEyIdM3QxbQ+8ORZmrjWj\nUU5sqzznx0+vmNbm4um2dYkfmgtj0nadv7+J/zUnDrcttK3rNcV0O7RsB1/+0awL7WLC3d0LBlu/\n/ge0MY/lX9l9gyqfyAQItRspUj6qAqo/qWiv6nwktYVSQ148491EbgweOdBcbHSh7qRmqC7hngrY\nnSImgsojT9Fan7FbfB14vrodaa3nA/PBTD/wi2oqHEJrzeH0PEL9vVm+4wQvfXWAs/klhPp74+/t\nzvj4djx7XSyt/BrxqtHifNNvnbIZek+BPrfCziVmbPbOJbDhVSpas2CuLty2sHJQg+m7/uEl87zH\ntebE6Lq/mlEpfW6C+Glm+lZtMYFd/qFVPnoDbMMPpy+vPJLC3h+Szp9cyr4L4WL6e5sCNzdzIvIy\nB59qG/WU+RuoOkNkM1eXcN8EdFVKRWNCfRpws30BpVRbrXX5KfIJwN56raVwmNe/P8pfVlb+57xp\nYAf+7/q4hm2h718FH80wwREWA1/8Ee783FyJeO60bTjetnfNT7l1fzWPQ+43rfVeN5qTjPs/N+un\nLzMX8QRFwdq/mL7tblebLg2lYNA9tiBWytZPbs++1T3uBTMErsPg88vZq/q7cpULs5444egamO6V\nsB61l2tmag13rXWpUup+4EvMUMg3tda7lVLPAJu11suBB5VSE4BSIBO4owHrLBpYcmY+CzccY/n2\nE5zKKcTPy50W3h4M7RLKI2O61c9UuqVF5jL49v1MYHv6Vu4D3f0pFOfCwdVmTpSyYvjvMDPEL8Qa\nrqPmmP7W7/5+/v7b9zcXnPiHm/3GToKY8aYl3mmEKWN/krVcbVPTQuUTcS1CYMgFZha8kBnfVPqC\nIUR9klkhBWDuM5qYcpav9qTx2vdHsGgY2SOMPpGtuGVQBwJ9PS++pb7oFtOy7T0NjqwzreFv/2Za\n2bcshU9+Y04eTn3XTPna/Wr4ak7NQwoBQrrAA9bRKKd2mps0dBoBi24y62Z8c+Fhapfq1E5zgjO4\nU8O9h2h45VfUXmhUTRMjs0KKWmmtKSyxsHBDEh9sTOZohrms/fq+7XlsbHfaBv6C4WH7vzCjQ678\nY+X1JQVmZMm+Feby9SPrzJjy8u6T9+y6PV6zDuE7sMpc3BIUbeZcAXORT49xZvjdF7PNsMNybXrB\nOOtpnt5TzYnSoOi61/1i1DRyQziX21fU7duaE5KWezN1MruAp5btZvUeM51u74hAbhrYgaFdQi+u\n26W8BfTgNnNCM32fOdHl5g7zR1z4teG94JoXzJSwpYXmqj+oPG3r7GRzFaXFYuY+CY+rvt+6tMjc\n/SY89pcfgxBOQFruolp7T+bw5Ke72HLMjFGOjwjk3hFd+FVseO3dLgVZ8PN8c5KzMMf0f7t5mImx\nyv2rLyh3M3/44unmSkl7w34He1eYlnmbONOSD2xvum1m/WTm/X5zLPScYH4GzjRXbpbPH+LmduFW\ns4e3BLsQSMu9Wcg8V8xDi7Zx7Ew+xzPNfBtdwvx54poYRnRrXbe+9LzTsPB6Mya8+zgzQVb5RFVg\nbkyQY70Ef9ij5kKb8kvfAyNNSLfpVfnqyawkc2Xo9GWV7xhfWmRCWghxHmm5N3Naa7Yez+LDTckk\npmSz71Qufl7u+Hq6M++WvozsUcN8F0k/mguA2vU1MwZ6B5g5VnZ8YLvYZ/9K8zh4lplrpEVriBoK\nP/3HzILYe6q50tDNw4wPt5+pz15QVPUnsiTYhbhk0nJ3QbtSs/nz53vYcCSTFl7uBPp68sx1cYzu\nWUOg55w0Iaw1PHOB6Ul9As3UsIe+NiNRIgdU3q616UJxwC3FhGgupOXezFgsmiVbklm9O42v951G\nKbhraDQzh3civKXP+S8oK4Uf/2Hu+gNmTu/yuTla9zCjUTpdYS6d//5FOLYeJr5qLuAJ7Xr+/sCc\n4JRgF6JJkHB3ciVlFl5cfYAFPyWRX1xGgI8Hof5eLP3NZUSFVpmjOuuYucdmaaEZYlh+f0kw07+W\nhJoAj7+p8kiUa//RKMcihKg/Eu5OSmvNBxuTeemr/WTkFdM7IpBbB3dkSv8ItAY3N2XGlYf1NKNT\nNr9h5lIptOvjjh4OR78zz6d9YO4s49/aMQckhKhXEu5OprCkjBWJJ/nvt4c5dNrcqedvk3uZ2Ri1\nBc4cRgV3gpSt5081C2aCrPLpaq+bZ+4uFD384qZ+FUI0WRLuTmRF4gkeXbKDwhILPdoE8MDILtwQ\nG0DHVbdD4O9hx/vmjkED7jb3drTXYQhM/A+0ijLDD7tdZW4IPHVhte8lhHBuMlqmibNYNP/65iBr\n9qZxOPU0P/g+ysFevyXhuvvxKMiAzx+BvZ+d/0JPP7juFVhqvZXZA1ttN0KwlJl5zF1lZkIhmhEZ\nLePEtNb8dOQMTy/fw+ncQrLyS4iPbMVL8ScI2Z9JSOKfoFMofPE4FJ6t/OLBs8zNJGImmJEr+1eZ\nmwrb3+HGRefSEELYSLg3MSfOFvDY0kR+OJSBm4Ke7Vpy6+COPOK3CrX2L7aCn94LkYPNfTotJbb1\nMePNDZXLTX698SovhGgyJNybAK01z63ax6akTFKyCigoLuGp8T2Z2uYEfhv+CedCYP37pvBtn8Bx\n6y3F+twKJeegrMTcLSgrydw4QgjR7Em4O1hOYQmz3t3KD4cy8KKE5wIWc533D7h3WQVv31L5JsTX\nzYPOI81POe8A2/Pa7r8phGg2JNwdpKC4jB8OZfDK2kPsOZHN/MGZDEl5g4CMbabAq9aulRsX2G7q\n3Ka3YyorhHA6Eu6NzGLRLN6czPNf7ifzXDHdPdOYN20MV30UZwpEX2H6zbe8YybQ6j4OJr0G654z\n0wIIIUQdSLg3kl2p2Xy99zQLNxwjI6+I1gHevHtFDkN//i3YzQJA6+4wcIb5Kdf7RvMjhBB1JOHe\nwNYfzuCJT3ZxNOMcv3LbyKseq1jQ40Ve9PovXkcO2Qq26QVRw2Hobx1XWSGEy5BwbyDl86nf+dYm\nikotRIX48b9zLwMwIOlaU0jZjTe/+2uZx1wIUW8k3BtAQXEZsz9OZNn2EwT6erKsw4d0zatyNe4V\ns2HQPWAphbJiCXYhRL2ScK9n+07l8NAH2zl4OpunL/Nm+s7bUSfyKxfqcS1c+bhjKiiEaBYk3OvJ\n0Yxz/OXzvazZm0aonwebo/5H8NbvbQVGPw0ePtD/dnD3clxFhRDNgoR7PcguKOH2N35mWsF7/Nv/\nK3xLs+GkXYF+02Howw6rnxCi+ZFwv0Svf3+Ef359kPCSFGZ5LoVS64bgzhDSxdymbsK/HVpHIUTz\nI+F+kfafyuXtxUs4eyqJX0XG83Tp23DGujEoGm54A9r1dWQVhRDNmIT7RdhyLJM739rID/oJWnrl\nQ5rdxjlZ4ObmsLoJIQRIuP9iq3ef4sFF23jQdzUti/MhYiD0udlM4OUXIsEuhGgSJNzrqLCkjD9+\ntIP9O9Zzc2ghs3LfhI5D4eYPwdvf0dUTQohKJNzr4FxRKTMWbCY26R0+934fcoHWMWZudQ8Z1iiE\naHok3Gtx/Ew+Mxdu5vDpHP4bvAHyAO9AuOrPEuxCiCZLwv0CzuQV8cAHW7k96xVu8vrSBPvkN6DX\nDY6umhBCXJCEew1SzxZwy/z1PJ/3BAPd9pqV8TdD3GTHVkwIIepAwr0ax86c48f/3MvDZdm2YP/1\nl2ZkjFKOrZwQQtRBncbtKaXGKqX2K6UOKaVmX6DcZKWUVko57V2aD6XlsPI/j3Jz2TImss6sfGQv\ndBgswxyFEE6j1pa7UsodmAeMAVKATUqp5VrrPVXKBQAPAT83REUbw5Zjmbz6xuu87va+bWXHy6Fl\nO8dVSgghLkJdmqIDgUNa6yNa62JgEXBdNeWeBf4GFNZj/RrN6ZxC7n13K7d6fmNbOX053PG54yol\nhBAXqS7h3h5ItltOsa6roJTqB0RqrZ0yCYtLLcx6byv/LX6cEWU/2Ta07i597EIIp3TJJ1SVUm7A\nS8AddSg7E5gJ0KFDh0t963pxJq+Ix979lr+fvJ9oN+skMTPXQXYqBLRxZNWEEOKi1aXlngpE2i1H\nWNeVCwDigHVKqSRgMLC8upOqWuv5WusErXVC69atL77W9eiF1QfomfyhLdgf2Gpmc4y51rEVE0KI\nS1CXlvsmoKtSKhoT6tOAm8s3aq2zgdDyZaXUOuBRrXWVm4Y2MVrz11V7+HTjATb5rQb/CBg4A0I6\nO7pmQghxyWoNd611qVLqfuBLwB14U2u9Wyn1DLBZa728oSvZEPLevoGJRw9wXctA/Itz4Ial0GGQ\no6slhBD1ok597lrrlcDKKuvm1FB2xKVXq2GV/DgP/2NriHEDbfGFSa9JsAshXEqzu0JV56bh+dUf\nASh198Pjri+hbW8H10oIIepXs7rkUmvNyi9WVCx73LJIgl0I4ZKaVbh/eyCd9B1fAKDb9IL2/R1c\nIyGEaBjNpltm27EzZLx7N3d4fEtZr2m4T/6fo6skhBANpnm03DMOcXbxfdzg/i2HO0/H/bp/ObpG\nQgjRoFy/5V6UB6/050qgyN2fzrf+S6YUEEK4PJdvuevXRtkWhj4swS6EaBZcu+Wel47K2McnZZfj\nM+EFru7fw9E1EkKIRuHSLfeCo2aGx21hkxibECM32xBCNBsunXabfvyaUu3G5GuvRUl3jBCiGXHZ\ncE86mQ6pWzjr0574aJm6VwjRvLhsuPu8ey3D3XcS0F762YUQzY9LhrultIQ25/YB4K3KHFwbIYRo\nfK4X7pYy1F/CbMsDZzquLkII4SCuNxTy2I8obQGg8IFd+IRE1vICIYRwPS7Xci/du5JC7cmcuK8k\n2IUQzZbLtdyzj2zmuO7I2L6dHF0VIYRwGNdquWuNb+YeDrt3YlB0iKNrI4QQDuNS4V5w+jB+lnN4\ntu+Du5tctCSEaL5cJ9wtFo78uBSATr2HOLgyQgjhWK4T7js+IDbxrwD07CPhLoRo3lwn3JM3VDx1\n9/J1YEWEEMLxXCbci08fAuCL/q85uCZCCOF4rhHuZaWoU4m8WzqKsPgxjq6NEEI4nGuE+/H1eJbm\n8ZPuRc+2LR1dGyGEcDjXCPf9X1CMFyfDhuLj6e7o2gghhMO5RLjrE1vZQxTdI2XediGEAFcId62x\nnNrNrtJI4iMCHV0bIYRoEpw/3M8ex704hz06it4RrRxdGyGEaBKcP9xP7QTgsFsU3cL9HVwZIYRo\nGpw/3NN2YUHh0TYOD3fnPxwhhKgPTp+GlpM7OabbyMlUIYSw4/ThXnoikd2WDvSWk6lCCFHBucO9\nMAev3OPssXSke5sAR9dGCCGaDOcO97TdAOynI9GhLRxcGSGEaDrqFO5KqbFKqf1KqUNKqdnVbP+N\nUmqnUmq7UuoHpVTP+q9qNdJ2AZDdsptcmSqEEHZqDXellDswD7ga6AncVE14v6+17qW17gM8D7xU\n7zWtTuZRCvGiZVhUo7ydEEI4i7q03AcCh7TWR7TWxcAi4Dr7AlrrHLvFFoCuvyrWTGce4ZgOp0u4\n9LcLIYQ9jzqUaQ8k2y2nAIOqFlJK3Qc8AngBI+uldrUoyTjMMUsYXVrLxUtCCGGv3k6oaq3naa07\nA38AnqyujFJqplJqs1Jqc3p6+qW9ocWCe/YxknQbOodJuAshhL26hHsqEGm3HGFdV5NFwMTqNmit\n52utE7TWCa1bt657LauTexL3siKO6zC6SLgLIUQldQn3TUBXpVS0UsoLmAYsty+glOpqt3gNcLD+\nqliDrKMA5Pt3INDXs8HfTgghnEmtfe5a61Kl1P3Al4A78KbWerdS6hlgs9Z6OXC/Umo0UAJkAbc3\nZKUByDTh7hvepcHfSgghnE1dTqiitV4JrKyybo7d84fquV61Ks04jNbutI6QcBdCiKrqFO5NUeHp\nQ2ToUCJD5J6pQghRlfNOP2Ad496ula+jayKEEE2Oc4a71njlHOeYDiciSMJdCCGqcs5wL8jCqzSX\nY4QT3tLH0bURQogmxznD3TpSJsenPV4eznkIQgjRkJwzGfPPAKD9whxcESGEaJqcM9yLzDxlXv5y\n9yUhhKiOc4Z7YTYAPv7BDq6IEEI0TU4Z7toa7i0CQxxcEyGEaJqc8iKmorws3LU7rVrKBUxCCFEd\npw33UvwIDfB2dFWEEKJJcspwLzl3ljztR6i/hLsQQlTHKfvcLYU55OAnU/0KIUQNnDLc3YqyydV+\ntPKTcBdCiOo4Z7gX55IrLXchhKiRU4a7e8k5zuGLv7dTnjIQQogG55Th7lmWT6mHH0opR1dFCCGa\nJOcMd0sBFg8/R1dDCCGaLOcL97ISPHUJ2lPCXQghauJ84V58zjx6+zu2HkII0YQ5bbgrLwl3IYSo\nifOFe0k+AGUecns9IYSoifOFe3EeABaPFg6uiBBCNF1OGO6mW8YiJ1SFEKJGThvuMlpGCCFq5rTh\nbvGUbhkhhKiJ04W7pcj0uWsJdyGEqJHThjveEu5CCFETp5t5q7SkGK3dcZOWuxBC1MjpWu75CbPo\nWrQQN0+5C5MQQtTE6cK9pMwCgJen033pEEKIRuN04V5casLd012m+xVCiJo4X7iXt9w9nK7qQgjR\naJwuISu6ZdydrupCCNFonC4hbd0yTld1IYRoNHVKSKXUWKXUfqXUIaXU7Gq2P6KU2qOUSlRKfa2U\n6lj/VTVKpFtGCCFqVWtCKqXcgXnA1UBP4CalVM8qxbYBCVrr3sBS4Pn6rmi5Imm5CyFEreqSkAOB\nQ1rrI1rrYmARcJ19Aa31Wq11vnVxAxBRv9W0KSnTAHh5yGgZIYSoSV3CvT2QbLecYl1Xk7uAVdVt\nUErNVEptVkptTk9Pr3st7ZSUlp9Qdb+o1wshRHNQr30bSqlbgQTg79Vt11rP11onaK0TWrdufVHv\nUT4U0lNa7kIIUaO6XOaZCkTaLUdY11WilBoNPAFcobUuqp/qna/8hKr0uQshRM3qkpCbgK5KqWil\nlBcwDVhuX0Ap1Rf4HzBBa326/qtpU1wq49yFEKI2tSak1roUuB/4EtgLLNZa71ZKPaOUmmAt9nfA\nH1iilNqulFpew+4umVyhKoQQtavT7Fta65XAyirr5tg9H13P9apRiQyFFEKIWjldQtqGQjpd1YUQ\notE4XUJ2DPFjXK820ucuhBAX4HSTol8V24arYts4uhpCCNGkSfNXCCFckIS7EEK4IAl3IYRwQRLu\nQgjhgiTchRDCBUm4CyGEC5JwF0IIFyThLoQQLkhprR3zxkqlA8cu8uWhQEY9VscZyDE3D3LMzcOl\nHHNHrXWtN8RwWLhfCqXUZq11gqPr0ZjkmJsHOebmoTGOWbplhBDCBUm4CyGEC3LWcJ/v6Ao4gBxz\n8yDH3Dw0+DE7ZZ+7EEKIC3PWlrsQQogLkHAXQggX5HThrpQaq5Tar5Q6pJSa7ej61Bel1JtKqdNK\nqV1264KVUl8ppQ5aH4Os65VS6l/W30GiUqqf42p+8ZRSkUqptUqpPUqp3Uqph6zrXfa4lVI+SqmN\nSqkd1mN+2ro+Win1s/XYPlRKeVnXe1uXD1m3Rzmy/hdLKeWulNqmlFphXXbp4wVQSiUppXYqpbYr\npTZb1zXa37ZThbtSyh2YB1wN9ARuUkr1dGyt6s3bwNgq62YDX2utuwJfW5fBHH9X689M4NVGqmN9\nKwV+p7XuCQwG7rP+e7rycRcBI7XW8UAfYKxSajDwN+AfWusuQBZwl7X8XUCWdf0/rOWc0UPAXrtl\nVz/ecldqrfvYjWlvvL9trbXT/ABDgC/tlh8HHnd0verx+KKAXXbL+4G21udtgf3W5/8DbqqunDP/\nAMuAMc3luAE/YCswCHO1ood1fcXfOfAlMMT63MNaTjm67r/wOCOsQTYSWAEoVz5eu+NOAkKrrGu0\nv22narkD7YFku+UU6zpXFa61Pml9fgoItz53ud+D9et3X+BnXPy4rV0U24HTwFfAYeCs1rrUWsT+\nuCqO2bo9Gwhp3BpfspeBxwCLdTkE1z7echpYrZTaopSaaV3XaH/bTneD7OZKa62VUi45blUp5Q98\nBDystc5RSlVsc8Xj1lqXAX2UUq2AT4AeDq5Sg1FKXQuc1lpvUUqNcHR9GtlQrXWqUioM+Eoptc9+\nY0P/bTtbyz0ViLRbjrCuc1VpSqm2ANbH09b1LvN7UEp5YoL9Pa31x9bVLn/cAFrrs8BaTLdEK6VU\neWPL/rgqjtm6PRA408hVvRSXAxOUUknAIkzXzD9x3eOtoLVOtT6exnyID6QR/7adLdw3AV2tZ9q9\ngGnAcgfXqSEtB263Pr8d0yddvn669Qz7YCDb7que01Cmif4GsFdr/ZLdJpc9bqVUa2uLHaWUL+Yc\nw15MyN9gLVb1mMt/FzcA32hrp6wz0Fo/rrWO0FpHYf6/fqO1vgUXPd5ySqkWSqmA8ufAVcAuGvNv\n29EnHS7iJMU44ACmn/IJR9enHo/rA+AkUILpb7sL09f4NXAQWAMEW8sqzKihw8BOIMHR9b/IYx6K\n6ZdMBLZbf8a58nEDvYFt1mPeBcyxru8EbAQOAUsAb+t6H+vyIev2To4+hks49hHAiuZwvNbj22H9\n2V2eVY35ty3TDwghhAtytm4ZIYQQdSDhLoQQLkjCXQghXJCEuxBCuCAJdyGEcEES7kII4YIk3IUQ\nwgX9P4LmiunbwPDsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "0xtcLtUJOmAm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}